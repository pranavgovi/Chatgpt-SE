[
  {
    "type": "javascript",
    "code": "exports default PromptGPT;\n"
  },
  {
    "type": "javascript",
    "code": "// ExampleStory.js (ESM module)\nimport { FetchStory } from './fetch-story-types';\n\nconst story: FetchStory = {\n  name: 'Fetch Data',\n  url: 'https://api.example.com/data',\n  init: {\n    method: 'GET',\n    headers: {\n      'Authorization': 'Bearer YOUR_ACCESS_TOKEN',\n      'Content-Type': 'application/json',\n    },\n  },\n  expect: {\n    status: 200,\n    headers: {\n      'Content-Type': 'application/json',\n    },\n  },\n};\n\nexport default story;\n"
  },
  {
    "type": "python",
    "code": "import numpy as np\n\nimg = np.fromfile(dph_files[0], dtype=np.uint16)\narray_size_bytes = img.nbytes\nprint(array_size_bytes)\n"
  },
  {
    "type": "python",
    "code": "filtered_users = [user for user in users if user[\"age\"] > 30]\n"
  },
  {
    "type": "java",
    "code": "import java.util.ArrayList;\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\n\npublic class KeywordMatcher {\n    public static void main(String[] args) {\n        // \ub300\uc870\ud560 \ud0a4\uc6cc\ub4dc\uc640 \ud574\ub2f9\ud558\ub294 \uc758\ubbf8\uc801\uc73c\ub85c \ube44\uc2b7\ud55c \ubb38\uc790\uc5f4\ub4e4\uc744 \ub9e4\ud551\ud558\ub294 \ub9f5\n        Map<String, List<String>> keywordMap = new HashMap<>();\n\n        // \ub300\uc870\ud560 \ud0a4\uc6cc\ub4dc\uc640 \ud574\ub2f9\ud558\ub294 \uc758\ubbf8\uc801\uc73c\ub85c \ube44\uc2b7\ud55c \ubb38\uc790\uc5f4\ub4e4\uc744 \ucd94\uac00\n        addSimilarMeaningData(keywordMap, \"apple\", \"fruit\", \"red\", \"healthy\");\n        addSimilarMeaningData(keywordMap, \"banana\", \"fruit\", \"yellow\", \"tropical\");\n        addSimilarMeaningData(keywordMap, \"date\", \"fruit\", \"sweet\", \"brown\");\n\n        // \ub300\uc870 \uacb0\uacfc \ucd9c\ub825\n        for (Map.Entry<String, List<String>> entry : keywordMap.entrySet()) {\n            String keyword = entry.getKey();\n            List<String> similarMeaningDataList = entry.getValue();\n\n            System.out.println(\"Keyword: \" + keyword);\n            System.out.println(\"Similar Meaning Data: \" + similarMeaningDataList);\n\n            // \ub300\uc870 \ud0a4\uc6cc\ub4dc\uc640 \ube44\uad50\ud558\uc5ec \uc720\uc0ac\ud55c \uc758\ubbf8\ub97c \uac00\uc9c4 \ub370\uc774\ud130\ub97c \ucd94\uac00\ud558\uac70\ub098 \ucc98\ub9ac\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n            for (String data : similarMeaningDataList) {\n                if (isSimilarToKeyword(data, keyword)) {\n                    // \uc720\uc0ac\ud55c \uc758\ubbf8\ub97c \uac00\uc9c4 \ub370\uc774\ud130 \ucc98\ub9ac\n                    System.out.println(\"Similar Data: \" + data);\n                }\n            }\n        }\n    }\n\n    // \ub300\uc870\ud560 \ud0a4\uc6cc\ub4dc\uc640 \uc758\ubbf8\uc801\uc73c\ub85c \ube44\uc2b7\ud55c \ubb38\uc790\uc5f4\ub4e4\uc744 \ucd94\uac00\ud558\ub294 \ud568\uc218\n    private static void addSimilarMeaningData(Map<String, List<String>> keywordMap, String keyword, String... similarMeaningData) {\n        keywordMap.put(keyword, new ArrayList<>());\n        for (String data : similarMeaningData) {\n            keywordMap.get(keyword).add(data);\n        }\n    }\n\n    // \ub450 \ubb38\uc790\uc5f4\uc774 \uc758\ubbf8\uc801\uc73c\ub85c \uc720\uc0ac\ud55c\uc9c0 \ud655\uc778\ud558\ub294 \ud568\uc218 (\uc608: \"apple\"\uacfc \"fruit\"\ub294 \uc720\uc0ac\ud568)\n    private static boolean isSimilarToKeyword(String data, String keyword) {\n        // \uc2e4\uc81c \uc720\uc0ac\uc131 \ube44\uad50 \ub85c\uc9c1\uc744 \uc5ec\uae30\uc5d0 \ucd94\uac00\ud558\uc138\uc694.\n        // \uc608: \ub2e8\uc5b4 \uc720\uc0ac\uc131 \ube44\uad50 \uc54c\uace0\ub9ac\uc998\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc720\uc0ac\ud55c\uc9c0 \ud655\uc778\n        return data.contains(keyword);\n    }\n}\n"
  },
  {
    "type": "ruby",
    "code": "Vagrant.configure(VAGRANTFILE_API_VERSION) do |config|\n  # General Vagrant Windows VM configuration.\n  config.vm.box = \"gusztavvargadr/windows-server-core\"\n  config.vm.communicator = \"winrm\"\n  config.winrm.username = \"your_windows_username\"\n  config.winrm.password = \"your_windows_password\"\n  config.vm.synced_folder \".\", \"/vagrant\", disabled: true\n  config.vm.provider :virtualbox do |v|\n    v.memory = 1024\n    v.cpus = 4\n    v.linked_clone = true\n  end\nend\n"
  },
  {
    "type": "javascript",
    "code": "server.listen(port, () => {\n  console.log(`Server is running on port ${port}`);\n});\n"
  },
  {
    "type": "javascript",
    "code": "const express = require('express');\nconst whisperRouter = require('./api/whisper');\nconst gptRouter = require('./api/gpt');\n\nconst app = express();\napp.use(express.json());\n\napp.use('/api/whisper', whisperRouter);\napp.use('/api/gpt', gptRouter);\n\nconst port = process.env.PORT || 3000;\napp.listen(port, () => console.log(`Server running on port ${port}`));\n"
  },
  {
    "type": "javascript",
    "code": "const express = require('express');\nconst path = require('path');\nconst fs = require('fs').promises;\nconst contentful = require('contentful');\nconst compression = require('compression');\n\n// Constants\nconst PORT = process.env.PORT || 5000;\nconst SPACE_ID = process.env.REACT_APP_SPACE_ID;\nconst ACCESS_TOKEN = process.env.REACT_APP_ACCESS_TOKEN;\nconst ENVIRONMENT = process.env.REACT_APP_ENVIRONMENT || 'master';\nconst MAIN_TITLE = \"IT jobs with salaries - Jobs For IT\";\nconst MAIN_DESCRIPTION = \"Job offers for software developers, testers, UX designers, DevOps\";\nconst MAIN_IMAGE = \"https://www.jobsforit.de/static/media/wiewior.4979dfde.png\";\nconst FILE_PATH = path.resolve(__dirname, '..', 'build', 'index.html');\n\n// Contentful client setup\nconst client = contentful.createClient({\n    space: SPACE_ID,\n    accessToken: ACCESS_TOKEN,\n    environment: ENVIRONMENT\n});\n\nconst getJob = slug => client.getEntries({\n    content_type: 'job',\n    'fields.slug': slug,\n    select: 'fields.ogTitle,fields.ogDescription,fields.ogImage,fields.position,fields.company,fields.city',\n    limit: 1,\n});\n\n// Server setup\nconst app = express();\n\n// Middleware\napp.use(compression());\napp.use(express.static(path.resolve(__dirname, '..', 'build')));\n\n// Routes\napp.get('/jobs/:id', async (request, response) => {\n    const id = request.params.id;\n    let data;\n\n    try {\n        data = await fs.readFile(FILE_PATH, 'utf8');\n        const entries = await getJob(id);\n        const { position, ogTitle, ogDescription, ogImage } = entries.items[0].fields;\n        const { name: company, logo } = entries.items[0].fields.company.fields;\n        const { name: city } = entries.items[0].fields.city.fields;\n\n        const title = ogTitle || `${position} Job - ${company} - ${city} - Jobs For IT`;\n        const description = ogDescription || `Working in IT: ${company} is looking for ${position}. Job ${city}.`;\n        const image = ogImage ? ogImage.fields.file.url : logo.fields.file.url;\n\n        data = data.replace(new RegExp(MAIN_TITLE, \"g\"), title);\n        data = data.replace(new RegExp(MAIN_DESCRIPTION, \"g\"), description);\n        data = data.replace(MAIN_IMAGE, \"https:\" + image);\n\n        response.send(data);\n    } catch (err) {\n        console.error(err);\n        if (data) {\n            response.send(data);\n        } else {\n            response.status(500).send('Internal server error');\n        }\n    }\n});\n\napp.get('/*', (req, res) => {\n    res.sendFile(FILE_PATH, function(err) {\n        if (err) {\n            res.status(500).send(err);\n        }\n    });\n});\n\n// Start the server\napp.listen(PORT, () => console.log(`Listening on port ${PORT}`));\n"
  },
  {
    "type": "javascript",
    "code": "// Dependencies and Libraries\nconst fs = require(\"fs\");\nconst path = require('path');\nconst contentful = require(\"contentful\");\nconst moment = require('moment');\nconst xmlFormatter = require('xml-formatter');\nconst { paramsApplier } = require(\"react-router-sitemap\");\n\n// Configuration Constants\nconst CONTENTFUL_CONFIG = {\n  space: process.env.REACT_APP_SPACE_ID || \"f6zwhql64w01\",\n  accessToken: process.env.REACT_APP_ACCESS_TOKEN || \"00b696c26342aa70ce936b551fe48e6548745fa637b6cd0c62fa72886af5bd78\",\n  environment: process.env.REACT_APP_ENVIRONMENT || \"master\"\n};\nconst client = contentful.createClient(CONTENTFUL_CONFIG);\n\n// Utility Functions\nasync function fetchContentfulEntries(contentType) {\n  try {\n    const entries = await client.getEntries({ content_type: contentType });\n    return entries.items.length > 0 ? entries.items : [];\n  } catch (error) {\n    console.error(`Error fetching ${contentType} entries:`, error);\n    return [];\n  }\n}\n\n// Sitemap Generation Functions\nfunction generatePathsBasedOnRoute(route) {\n  const config = { [route.path]: [{ ...route.params }] };\n  return paramsApplier([route.path], config);\n}\n\nfunction generateSitemap(routes) {\n  const date = moment().format('YYYY-MM-DD');\n  const host = 'https://jobsforit.de';\n\n  const xml = `<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n      <urlset xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\">\n      ${routes.map(route => `<url><loc>${host + route}</loc><lastmod>${date}</lastmod></url>`).join(\"\")}\n      </urlset>`;\n\n  return xmlFormatter(xml);\n}\n\n// Main Execution\nasync function sitemapGenerator() {\n  try {\n    console.log('Starting sitemap generation...');\n\n    const technologies = (await fetchContentfulEntries(\"technology\")).map(tech => tech.fields.name.toLowerCase());\n    const cities = (await fetchContentfulEntries(\"city\")).map(city => city.fields.name.toLowerCase());\n    const jobs = (await fetchContentfulEntries('job')).map(job => encodeURIComponent(job.fields.slug));\n\n    const routes = [\n      // ... (Your original routes declaration goes here)\n    ];\n\n    const newRoutes = routes.flatMap(generatePathsBasedOnRoute);\n\n    console.log('Saving sitemap to public/sitemap.xml');\n    fs.writeFileSync(path.join(process.cwd(), 'public', 'sitemap.xml'), generateSitemap(newRoutes));\n    console.log('Sitemap generation completed.');\n\n  } catch (error) {\n    console.error('Error generating sitemap:', error);\n  }\n}\n\nsitemapGenerator();\n"
  },
  {
    "type": "python",
    "code": "import PySimpleGUI as sg\nfrom translate import translate_text, LANGUAGES\n\ndef create_window():\n    sg.theme(\"LightGreen\")\n\n    layout = [\n        [\n            sg.Text(\"Choose a language to translate to:\"),\n            sg.Combo(list(LANGUAGES.values()), key=\"-LANG-\", size=(20, 1)),\n        ],\n        [\n            sg.Text(\"Enter text to translate:\"),\n            sg.InputText(key=\"-TEXT-\", size=(50, 5), enable_events=True)\n        ],\n        [sg.Button(\"Translate\"), sg.Button(\"Exit\")],\n        [sg.Text(\"Translation output:\", size=(40, 1))],\n        [sg.Listbox(values=[], size=(60, 10), key=\"-OUTPUT-\", font=(\"Helvetica\", 12))],\n    ]\n\n    return sg.Window(\"Text Translator\", layout, font=(\"Helvetica\", 14))\n\ndef main():\n    window = create_window()\n    \n    # List to store translations in the format \"original - translated\"\n    translations = []\n\n    while True:\n        event, values = window.read()\n\n        if event == sg.WINDOW_CLOSED or event == \"Exit\":\n            break\n        \n        # Check if \"Translate\" button is clicked or Enter key is pressed in the InputText element\n        if event == \"Translate\" or (event == '-TEXT-' and values['-TEXT-'].endswith('\\n')):\n            target_language_key = {v: k for k, v in LANGUAGES.items()}[values[\"-LANG-\"]]\n            original_text = values[\"-TEXT-\"].strip()  # Remove trailing newline\n            translated_text = translate_text(original_text, target=target_language_key)\n            \n            # Create a new entry for the translation\n            translation_entry = f\"{original_text} - {translated_text}\"\n            \n            # Insert the new entry at the beginning of the translations list\n            translations.insert(0, translation_entry)\n            \n            # Update the Listbox element to display the updated translations list\n            window['-OUTPUT-'].update(translations)\n\n    window.close()\n\nif __name__ == \"__main__\":\n    main()\n"
  },
  {
    "type": "c",
    "code": "#include \"prot_queue.h\"\n#include <assert.h>\n#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n\n#define TEST_BUF_SIZE 10  // For simplicity\n\nstatic void test_queue_init_pop_push() {\n    struct prot_queue q;\n    int buffer[TEST_BUF_SIZE];\n    int data;\n\n    // Initialize\n    assert(prot_queue_init(&q, buffer, sizeof(buffer), sizeof(int)) == 1);\n\n    // Push and Pop\n    data = 5;\n    assert(prot_queue_push(&q, &data) == 1);\n    assert(prot_queue_pop(&q, &data) == 1);\n    assert(data == 5);\n\n    // Push to full, and then fail to push\n    for (int i = 0; i < TEST_BUF_SIZE; i++) {\n        assert(prot_queue_push(&q, &i) == 1);\n    }\n    assert(prot_queue_push(&q, &data) == 0);  // Should fail as queue is full\n\n    // Pop to empty, and then fail to pop\n    for (int i = 0; i < TEST_BUF_SIZE; i++) {\n        assert(prot_queue_try_pop(&q, &data) == 1);\n        assert(data == i);\n    }\n    assert(prot_queue_try_pop(&q, &data) == 0);  // Should fail as queue is empty\n}\n\n// This function will be used by threads to test thread safety.\nvoid* thread_func(void* arg) {\n    struct prot_queue* q = (struct prot_queue*) arg;\n    int data;\n\n    for (int i = 0; i < 100; i++) {\n        data = i;\n        prot_queue_push(q, &data);\n        prot_queue_pop(q, &data);\n    }\n    return NULL;\n}\n\nstatic void test_queue_thread_safety() {\n    struct prot_queue q;\n    int buffer[TEST_BUF_SIZE];\n    pthread_t threads[2];\n\n    assert(prot_queue_init(&q, buffer, sizeof(buffer), sizeof(int)) == 1);\n\n    // Create threads\n    for (int i = 0; i < 2; i++) {\n        pthread_create(&threads[i], NULL, thread_func, &q);\n    }\n\n    // Join threads\n    for (int i = 0; i < 2; i++) {\n        pthread_join(threads[i], NULL);\n    }\n\n    // After all operations, the queue should be empty\n    int data;\n    assert(prot_queue_try_pop(&q, &data) == 0);\n}\n\nint main(int argc, const char *argv[]) {\n    test_basic_event();\n    test_empty_tags();\n    test_parse_json();\n    test_parse_contact_list();\n    test_strings_work_before_finalization();\n    test_tce();\n    test_tce_command_result();\n    test_tce_eose();\n    test_tce_command_result_empty_msg();\n    test_content_len();\n    test_nostr_report();\n    test_queue_init_pop_push();          // Added\n    test_queue_thread_safety();          // Added\n    printf(\"All tests passed!\\n\");       // Print this if all tests pass.\n}\n"
  },
  {
    "type": "python",
    "code": "rsync_command = [\n    \"rsync\", \"-abP\", \"--delete\", \"--delete-excluded\"\n]\n\nif previous_version_path is not None:\n    rsync_command.append(\"--link-dest=\" + previous_version_path)\n\nrsync_command.extend([source_path, current_version_path])\n"
  },
  {
    "type": "javascript",
    "code": "function insertGitFetchCommand(user, repo, prNum) {\n  // Create the div that contains the fetch command.\n  var fetchDiv = document.createElement(\"div\");\n  fetchDiv.style.display = \"inline-flex\"; // Make the div only as wide as its content.\n  fetchDiv.style.flexDirection = \"column\";\n  fetchDiv.style.alignItems = \"flex-start\";\n  fetchDiv.style.background = \"#24292e\"; // Dark grey\n  fetchDiv.style.color = \"#ffffff\"; // White\n  fetchDiv.style.padding = \"10px\";\n  fetchDiv.style.border = \"1px solid #e1e4e8\";\n  fetchDiv.style.borderRadius = \"6px\";\n  fetchDiv.style.marginTop = \"10px\";\n\n  var commandTypes = [\n    { name: \"fetch\", command: `git fetch https://github.com/${user}/${repo}.git +refs/pull/${prNum}/head` },\n    { name: \"fetch+checkout\", command: `git fetch https://github.com/${user}/${repo}.git +refs/pull/${prNum}/head && git checkout FETCH_HEAD` },\n    { name: \"fetch+merge\", command: `git fetch https://github.com/${user}/${repo}.git +refs/pull/${prNum}/head && git merge FETCH_HEAD` },\n    { name: \"fetch+cherry-pick\", command: `git fetch https://github.com/${user}/${repo}.git +refs/pull/${prNum}/head && git cherry-pick FETCH_HEAD` },\n  ];\n\n  var radiosDiv = document.createElement(\"div\");\n  radiosDiv.style.display = \"flex\";\n  radiosDiv.style.justifyContent = \"space-between\";\n  radiosDiv.style.width = \"100%\";\n  radiosDiv.style.marginBottom = \"10px\";\n\n  commandTypes.forEach(function(type, index) {\n    var radio = document.createElement(\"input\");\n    radio.type = \"radio\";\n    radio.id = \"commandType\" + index;\n    radio.name = \"commandType\";\n    radio.value = type.name;\n    radio.checked = index === 0; // Select the first radio button by default.\n    radiosDiv.appendChild(radio);\n\n    var label = document.createElement(\"label\");\n    label.htmlFor = radio.id;\n    label.textContent = type.name;\n    radiosDiv.appendChild(label);\n  });\n\n  fetchDiv.appendChild(radiosDiv);\n\n  var preElement = document.createElement(\"pre\");\n  preElement.textContent = commandTypes[0].command;\n  preElement.style.cursor = \"pointer\";\n  preElement.title = \"Click to copy\";\n  fetchDiv.appendChild(preElement);\n\n  var copiedText = document.createElement(\"span\");\n  copiedText.style.visibility = \"hidden\";\n  copiedText.textContent = \"Copied!\";\n  fetchDiv.appendChild(copiedText);\n\n  radiosDiv.addEventListener(\"change\", function() {\n    var selectedType = document.querySelector('input[name=\"commandType\"]:checked').value;\n    var selectedCommand = commandTypes.find(function(type) {\n      return type.name === selectedType;\n    }).command;\n    preElement.textContent = selectedCommand;\n  });\n\n  preElement.addEventListener(\"click\", function() {\n    var commandToCopy = preElement.textContent;\n    navigator.clipboard.writeText(commandToCopy);\n    copiedText.style.visibility = \"visible\";\n    setTimeout(function() {\n      copiedText.style.visibility = \"hidden\";\n    }, 2000); // hide \"Copied!\" after 2 seconds\n  });\n\n  // Add the div to the page.\n  var header = document.getElementById(\"partial-discussion-header\");\n  header.parentNode.insertBefore(fetchDiv, header.nextSibling ? header.nextSibling.nextSibling : null);\n}\n"
  },
  {
    "type": "javascript",
    "code": "// ... (rest of the code)\n\nexport {\n    Speak,\n    ResetCache\n};\n"
  },
  {
    "type": "python",
    "code": "#!/usr/bin/env python\n\nimport sys\nfrom argparse import ArgumentParser, FileType\nfrom configparser import ConfigParser\nfrom confluent_kafka import Consumer, OFFSET_BEGINNING\n\nif __name__ == '__main__':\n    # Parse the command line.\n    parser = ArgumentParser()\n    parser.add_argument('config_file', type=FileType('r'))\n    parser.add_argument('--reset', action='store_true')\n    parser.add_argument('--group-id', type=str, help='Consumer group ID')\n    args = parser.parse_args()\n\n    # Parse the configuration.\n    # See https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md\n    config_parser = ConfigParser()\n    config_parser.read_file(args.config_file)\n    config = dict(config_parser['default'])\n    config.update(config_parser['consumer'])\n\n    # Set the group.id in the configuration\n    if args.group_id:\n        config['group.id'] = args.group_id\n\n    # Create Consumer instance\n    consumer = Consumer(config)\n\n    # Set up a callback to handle the '--reset' flag.\n    def reset_offset(consumer, partitions):\n        if args.reset:\n            for p in partitions:\n                p.offset = OFFSET_BEGINNING\n            consumer.assign(partitions)\n\n    # Subscribe to topic\n    topic = \"purchases\"\n    consumer.subscribe([topic], on_assign=reset_offset)\n\n    # Poll for new messages from Kafka and print them.\n    try:\n        while True:\n            msg = consumer.poll(1.0)\n            if msg is None:\n                # Initial message consumption may take up to\n                # `session.timeout.ms` for the consumer group to\n                # rebalance and start consuming\n                print(\"Waiting...\")\n            elif msg.error():\n                print(\"ERROR: %s\".format(msg.error()))\n            else:\n                # Extract the (optional) key and value, and print.\n\n                print(\"Consumed event from topic {topic}: key = {key:12} value = {value:12}\".format(\n                    topic=msg.topic(), key=msg.key().decode('utf-8'), value=msg.value().decode('utf-8')))\n    except KeyboardInterrupt:\n        pass\n    finally:\n        # Leave group and commit final offsets\n        consumer.close()\n"
  },
  {
    "type": "python",
    "code": "import pandas as pd\nimport os\nimport openpyxl\nimport numpy as np\n\n# Define the output file name\noutput_file = 'trabajo_cotidiano_semestral.xlsx'\n\n# Create an empty DataFrame to hold all the data\ndataframe = pd.DataFrame()\n\n# Keep track of the most recently modified file and its modification time\nmost_recent_file = None\nmost_recent_time = 0\n\n# Keep track of the sum of all values in cell 'C3' (which is at index (2, 2))\ntotal_puntos = 0\n\n# Loop over every file in the directory\nfor file in os.listdir():\n    # Check if the file is an xlsm file\n    if file.endswith('.xlsm'):\n        # Check the file modification time\n        mod_time = os.path.getmtime(file)\n        if mod_time > most_recent_time:\n            most_recent_time = mod_time\n            most_recent_file = file\n\n        # Load the workbook\n        workbook = openpyxl.load_workbook(file, read_only=True, data_only=True)\n\n        # Check each sheet\n        for sheet in workbook.sheetnames:\n            # If the sheet name contains 'dashboard' (case-insensitive)\n            if 'dashboard' in sheet.lower():\n                # Use openpyxl to get the 'C3' value directly\n                ws = workbook[sheet]\n                total_puntos += ws['C3'].value if ws['C3'].value else 0\n                \n                # Load the data into a DataFrame using pandas\n                df = pd.read_excel(file, sheet_name=sheet)\n\n                # Extract data from row 8 to 37 of the third column (column 'C' in Excel)\n                column_data = df.iloc[7:37, 2]\n\n                # Add the data to the final DataFrame\n                dataframe[file] = column_data.reset_index(drop=True)\n\n# Add a 'Total' column as the first column of the DataFrame\ndataframe.insert(0, 'Total', dataframe.sum(axis=1))\n\n# If there was at least one .xlsm file\nif most_recent_file is not None:\n    # Load the workbook\n    workbook = openpyxl.load_workbook(most_recent_file, data_only=True)\n\n    # Find the dashboard sheet\n    for sheet in workbook.sheetnames:\n        if 'dashboard' in sheet.lower():\n            # Load the data into a DataFrame\n            df = pd.read_excel(most_recent_file, sheet_name=sheet)\n\n            # Extract data from row 8 to 37 of the second column (column 'B' in Excel)\n            column_b_data = df.iloc[7:37, 1]\n\n            # Insert this data to the left of the 'Total' column\n            dataframe.insert(0, 'Estudiantes', column_b_data.reset_index(drop=True))\n\n# Write the final DataFrame to the output file\ndataframe.to_excel(output_file, index=False)\n\n# Multiply the total puntos by 3\ntotal_puntos *= 3\n\n# Load the final workbook\nworkbook = openpyxl.load_workbook(output_file)\n\n# Select the first sheet\nsheet = workbook.active\n\n# Write \"Total Puntos:\" to cell 'C35'\nsheet['C35'] = \"Total Puntos:\"\n\n# Write the total puntos to cell 'D35'\nsheet['D35'] = total_puntos\n\n# Save the workbook\nworkbook.save(output_file)\n\n# Now let's add the 'Nota' and 'Porcentaje' columns to the dataframe and save it again\n\n# Load the dataframe\ndf = pd.read_excel(output_file)\n\n# Create a new column 'Nota' after 'Estudiantes' and fill it with 'Total' * (100 / total_puntos)\ndf.insert(1, 'Nota', df['Total'] * (100 / total_puntos))\n\n# Round 'Nota' based on the specified rules\ndf['Nota'] = np.where((df['Nota'] % 1) < 0.5, np.floor(df['Nota']), np.ceil(df['Nota']))\ndf['Nota'] = df['Nota'].apply(lambda x: round(x, 2))\n\n# Create a new column 'Porcentaje' after 'Nota' and fill it with 'Nota' * 0.6\ndf.insert(2, 'Porcentaje', df['Nota'] * 0.6)\n\n# Round 'Porcentaje' based on the specified rules\ndf['Porcentaje_rondeado'] = np.where((df['Porcentaje'] % 1) < 0.5, np.floor(df['Porcentaje']), np.ceil(df['Porcentaje']))\ndf['Porcentaje_rondeado'] = df['Porcentaje_rondeado'].apply(lambda x: round(x, 2))\n\n# Rename 'Total' to 'Puntos Obtenidos'\ndf = df.rename(columns={'Total': 'Puntos Obtenidos'})\n\n# Reorder the columns to have 'Porcentaje_rondeado' as the third column\ncolumns = df.columns.tolist()\ncolumns = columns[:2] + ['Porcentaje_rondeado'] + columns[2:]\ndf = df[columns]\n\n# Save the updated dataframe back to the output file\ndf.to_excel(output_file, index=False)\n"
  },
  {
    "type": "javascript",
    "code": "const { createTasksFromCsv, createTasksFromJson } = require('../usecases/createTaskUseCase');\n\n// Get file path from command-line arguments\nconst filePath = process.argv[2];\n\nif (!filePath) {\n  console.error('Please provide a file path as an argument.');\n  process.exit(1);\n}\n\n// Determine file extension\nconst fileExtension = filePath.split('.').pop();\n\n// Call appropriate use case based on file extension\nif (fileExtension === 'csv') {\n  createTasksFromCsv(filePath);\n} else if (fileExtension === 'json') {\n  createTasksFromJson(filePath);\n} else {\n  console.error('Unsupported file extension. Please provide a CSV or JSON file.');\n}\n"
  },
  {
    "type": "java",
    "code": "@RestController\n@RequestMapping(\"/api\")\n@CrossOrigin(\"http://localhost:5173/\")\npublic class UserController {\n    // Other code in the class...\n\n    @Autowired\n    private AuthenticationService authenticationService;\n\n    @GetMapping(\"/form\")\n    public RedirectView redirectToFormPage(@RequestHeader(\"Authorization\") String token) {\n        // Check if the token is valid\n        if (!authenticationService.isTokenValid(token)) {\n            // Token is invalid, redirect to the login page\n            return new RedirectView(\"/login\");\n        }\n\n        // Token is valid, redirect to the form page\n        return new RedirectView(\"/form-page\");\n    }\n\n    // Other code in the class...\n}\n"
  },
  {
    "type": "javascript",
    "code": "import React, { useContext } from 'react';\n\nimport style from './style.module.scss';\nimport { ThemeContext } from \"../../themeContext\";\n\nconst SearchStatistics = ({ items }) => {\n    const themeContext = useContext(ThemeContext);\n\n    const classes = [style.SearchStatistics];\n    \n    if (themeContext.theme === 'dark') {\n        classes.push(style.SearchStatistics_dark);\n    } else {\n        classes.push(style.SearchStatistics_light);\n    }\n\n    return (\n        <ul className={classes.join(' ')}>\n            {items.map(item => (\n                <li\n                    key={item.label}\n                    className={style.SearchStatistics__item}\n                >\n                    <span className={style.SearchStatistics__itemValue}>\n                        {item.value}\n                    </span>\n                    <span className={style.SearchStatistics__itemLabel}>\n                        {item.label}\n                    </span>\n                </li>\n            ))}\n        </ul>\n    );\n}\n\nexport default SearchStatistics;\n"
  },
  {
    "type": "javascript",
    "code": "// src/index.js\n\nimport React from 'react';\nimport { render } from 'react-dom';\nimport { Router } from 'react-router-dom';\nimport App from './App';\nimport SetupFontAwesome from './utils/setupFontAwesome';\nimport SetupFacebookProvider from './utils/setupFacebookProvider';\n\n// ...other imports and initializations\n\nrender(\n  <Router history={history}>\n    <SetupFacebookProvider appId=\"Your-App-ID\">\n      <SetupFontAwesome />\n      <App />\n    </SetupFacebookProvider>\n  </Router>,\n  document.getElementById('root')\n);\n"
  },
  {
    "type": "javascript",
    "code": "document.addEventListener(\"DOMContentLoaded\", function () {\n    // Function to generate a random color in hexadecimal format\n    function getRandomColor() {\n        const letters = '0123456789ABCDEF';\n        let color = '#';\n        for (let i = 0; i < 6; i++) {\n            color += letters[Math.floor(Math.random() * 16)];\n        }\n        return color;\n    }\n\n    // Function to change the color of a box\n    function changeBoxColor(box) {\n        box.style.backgroundColor = getRandomColor();\n    }\n\n    // Function to add a palette to the history\n    function addPaletteToHistory(paletteColors) {\n        const paletteHistory = document.querySelector('.palette-set');\n        const listItem = document.createElement('li');\n\n        // Create mini squares for each color in the palette\n        paletteColors.forEach(function (color) {\n            const miniSquare = document.createElement('span');\n            miniSquare.className = 'mini-square';\n            miniSquare.style.backgroundColor = color;\n            listItem.appendChild(miniSquare);\n        });\n\n        // Create a copy button\n        const copyButton = document.createElement('button');\n        copyButton.className = 'copy-button';\n        copyButton.addEventListener('click', function () {\n            // Copy the palette hex codes to the clipboard\n            const hexCodes = paletteColors.join(', ');\n            navigator.clipboard.writeText(hexCodes).then(function () {\n                alert('Palette copied to clipboard: ' + hexCodes);\n            }).catch(function (error) {\n                console.error('Clipboard write error: ', error);\n            });\n        });\n\n        // Add a copy icon to the copy button\n        const copyIcon = document.createElement('span');\n        copyIcon.className = 'copy-icon';\n        copyButton.appendChild(copyIcon);\n\n        // Create a delete button\n        const deleteButton = document.createElement('button');\n        deleteButton.className = 'delete-button';\n        deleteButton.addEventListener('click', function () {\n            // Remove the palette item when the delete button is clicked\n            listItem.remove();\n        });\n\n        // Add a delete icon to the delete button\n        const deleteIcon = document.createElement('span');\n        deleteIcon.className = 'delete-icon';\n        deleteButton.appendChild(deleteIcon);\n\n        listItem.appendChild(copyButton);\n        listItem.appendChild(deleteButton);\n        paletteHistory.appendChild(listItem);\n    }\n\n    // Add a click event listener to the \"Randomize\" button\n    const randomizeButton = document.querySelector('.randomize-button');\n    if (randomizeButton) {\n        randomizeButton.addEventListener('click', function () {\n            const colorBoxes = document.querySelectorAll('.color-box');\n            const paletteColors = [];\n            colorBoxes.forEach(function (box) {\n                const newColor = getRandomColor();\n                changeBoxColor(box);\n                paletteColors.push(newColor);\n            });\n            addPaletteToHistory(paletteColors);\n        });\n    }\n});\n"
  },
  {
    "type": "ruby",
    "code": "deb http://ppa.launchpad.net/certbot/certbot/ubuntu mantic main\n"
  },
  {
    "type": "javascript",
    "code": "import { render } from 'solid-js/web';\nimport App from './App';\n\nrender(App, document.getElementById('app'));\n"
  },
  {
    "type": "javascript",
    "code": "import express from 'express';\nimport cors from 'cors';\nimport { createPrompt } from './prompt/createPrompt.js';\nimport { saveAndSendPrompt } from './interactiveSession/saveAndSendPrompt.js';\nimport api from './api.js'; // Import your api object\n\nconst app = express();\n\n// Enable CORS for all routes\napp.use(cors());\n\napp.use(express.json());\n\napp.post('/generate', async (req, res) => {\n  const { notes } = req.body;\n  const { prompt, saveto } = await createPrompt(notes);\n  const result = await saveAndSendPrompt(prompt, saveto, null, api); // pass the api object here\n  res.json({ prompt: result });\n});\n\napp.listen(3000, () => {\n  console.log('Server is running on port 3000');\n});\n"
  },
  {
    "type": "javascript",
    "code": "src/prompt/createPrompt.js:\n\nimport { readAttention } from \"../attention/readAttention.js\"\nimport util from 'util';\nimport fs from 'fs';\nimport yaml from 'js-yaml';\nimport ejs from 'ejs';\nimport { getPromptFlag } from './getPromptFlag.js';\nimport { getSystemPromptIfNeeded } from './getSystemPromptIfNeeded.js';\nimport { resolveTemplateVariables } from './resolveTemplateVariables.js';\nconst readFile = util.promisify(fs.readFile);\n\nconst createPrompt = async (userInput) => {\n  const promptDescriptor = yaml.load(await readFile(getPromptFlag() || \"prompt/prompt-list.yaml\", \"utf8\"));\n  let templateVars = Object.keys(promptDescriptor)\n    .filter(key => ['task', 'format', 'attention', 'saveto'].indexOf(key) < 0)\n    .reduce((obj, key) => {\n      obj[key] = promptDescriptor[key];\n      return obj;\n    }, {});\n\n  templateVars = await resolveTemplateVariables(templateVars);\n\n  const attention = await readAttention(promptDescriptor.attention);\n  const task = await ejs.renderFile(promptDescriptor.task, templateVars, {async: true});\n  const format = await ejs.renderFile(promptDescriptor.format, templateVars, {async: true});\n  const system = await getSystemPromptIfNeeded();\n  const saveto = promptDescriptor.saveto;\n  return {\n    prompt: `${system}# Working set\\n\\n${attention.join(\"\\n\")}\\n\\n# Task\\n\\n${task}\\n\\n# Output Format\\n\\n${format}\\n\\n${userInput ? userInput : \"\"}`,\n    saveto\n  };\n}\n\nexport { createPrompt };\n"
  },
  {
    "type": "javascript",
    "code": "import fs from 'fs';\nimport path from 'path';\nimport util from 'util';\nimport { processPath } from './filesystem.js';\nimport { processInterfaceSection } from './processInterfaceSection.js';\n\nconst readFile = util.promisify(fs.readFile);\n\nexport const readAttention = async (attentionArray = [], attentionRootDir = '.') => {\n  try {\n    const processedLines = await Promise.all(attentionArray.map(line => {\n      const trimmedLine = line.trim();\n      if (trimmedLine.endsWith(' iface')) {\n        const filePath = trimmedLine.slice(0, -6).trim();\n        return processInterfaceSection(attentionRootDir, filePath);\n      } else {\n        return processPath(attentionRootDir, trimmedLine);\n      }\n    }));\n    return processedLines;\n  } catch (error) {\n    console.warn(error);\n    throw new Error(\"Error processing attention lines!\");\n  }\n};\n"
  },
  {
    "type": "javascript",
    "code": "import * as marked from 'marked';\n"
  },
  {
    "type": "javascript",
    "code": "const creator = context.payload.sender.login;\n\nconst opts = github.rest.issues.listForRepo.endpoint.merge({\n  ...context.issue,\n  creator,\n  state: 'all',\n});\n\nconst issues = await github.paginate(opts);\n\nlet isAlreadyContributor = false;\n\nfor (const issue of issues) {\n  if (issue.number === context.issue.number) {\n    continue;\n  }\n  if (issue.pull_request && issue.user.login === creator) {\n    isAlreadyContributor = true;\n    break;\n  }\n}\n\nif (!isAlreadyContributor) {\n  await github.rest.issues.addLabels({\n    issue_number: context.issue.number,\n    owner: context.repo.owner,\n    repo: context.repo.repo,\n    labels: ['new contributor'],\n  });\n}\n"
  },
  {
    "type": "javascript",
    "code": "// Step 1: Store the current parent of the referencePlane\nvar originalParent = referencePlane.parent;\n\n// Step 2: Remove the referencePlane from its current parent\nif (originalParent) {\n    originalParent.remove(referencePlane);\n}\n\n// Step 3: Reset the position, rotation, and scale of the referencePlane\nreferencePlane.position.set(0, 0, 0);\nreferencePlane.rotation.set(0, 0, 0);\nreferencePlane.scale.set(1, 1, 1);\n\n// [Do your diagnostics here]\n\n// Step 4: Re-add the referencePlane to its original parent and restore its original transformation if necessary\nif (originalParent) {\n    originalParent.add(referencePlane);\n    \n    // If you stored the original transformation, apply it here\n    // For example:\n    // referencePlane.position.copy(originalPosition);\n    // referencePlane.rotation.copy(originalRotation);\n    // referencePlane.scale.copy(originalScale);\n}\n"
  },
  {
    "type": "c",
    "code": "syslog(LOG_DEBUG, \"Your log message here\");\n"
  },
  {
    "type": "javascript",
    "code": "import React from 'react';\nimport style from './Timeline.module.scss';\n\nconst Timeline = ({ steps, currentStep }) => {\n    return (\n        <ul className={style.Timeline}>\n            {steps.map((step, index) => {\n                const stepClasses = [style.Timeline_item];\n                \n                if(index + 1 < currentStep) {\n                    stepClasses.push(style.Timeline_item__completed);\n                } else if(currentStep === index + 1) {\n                    stepClasses.push(style.Timeline_item__current);\n                }\n\n                return (\n                    <li className={stepClasses.join(' ')} key={index}>\n                        <div className={style.Timeline_item_circle}></div>\n                        <span className={style.Timeline_item_text}>{step}</span>\n                    </li>\n                )\n            })}\n        </ul>\n    );\n}\n\nexport default Timeline;\n"
  },
  {
    "type": "javascript",
    "code": "import React from 'react';\nimport style from './Heading.module.scss';\n\nconst Heading = ({ theme, className, variant, children }) => {\n    const classes = [style.Heading];\n\n    // Handle theme styles\n    if (theme === 'dark') {\n        classes.push(style.Heading_white);\n    } else {\n        classes.push(style.Heading_black);\n    }\n\n    // Handle optional classname\n    if (className) {\n        classes.push(className);\n    }\n\n    // Handle variant styles\n    if (variant.includes('regular')) {\n        classes.push(style.Heading_regular);\n    }\n    if (variant.includes('h1')) {\n        classes.push(style.Heading_h1);\n    } else if (variant.includes('h2')) {\n        classes.push(style.Heading_h2);\n    } else if (variant.includes('h3')) {\n        classes.push(style.Heading_h3);\n    }\n\n    // Create the heading tag based on the variant\n    const Tag = variant.includes('h1') ? 'h1' : \n                variant.includes('h2') ? 'h2' : 'h3';\n                \n    return <Tag className={classes.join(' ')}>{children}</Tag>;\n};\n\nexport default Heading;\n"
  },
  {
    "type": "javascript",
    "code": "// deploy.js\nconst fs = require('fs');\nconst path = require('path');\n\n// Pfad zur index.html\nconst indexPath = path.join(__dirname, 'build', 'index.html');\n\n// Lese index.html\nfs.readFile(indexPath, 'utf8', function (err, data) {\n  if (err) {\n    return console.log(err);\n  }\n\n  // Erstelle 404.html\n  fs.writeFile(path.join(__dirname, 'build', '404.html'), data, 'utf8', function (err) {\n     if (err) return console.log(err);\n  });\n\n  // F\u00fcge Umleitungsskript hinzu\n  const redirectScript = `\n    <script>\n      (function(){\n        var redirect = sessionStorage.redirect;\n        delete sessionStorage.redirect;\n        if (redirect && redirect != location.href) {\n          history.replaceState(null, null, redirect);\n        }\n      })();\n    </script>\n  `;\n  const result = data.replace('<body>', '<body>' + redirectScript);\n\n  // Schreibe die \u00c4nderungen zur\u00fcck zu index.html\n  fs.writeFile(indexPath, result, 'utf8', function (err) {\n     if (err) return console.log(err);\n  });\n});\n"
  },
  {
    "type": "javascript",
    "code": "DOM.btnSubmitPlugin.addEventListener(\"click\", async () => {\n    const pluginData = {\n        name: DOM.inputPluginName.value,\n        creator: DOM.inputPluginCreator.value,\n        currentVersion: DOM.inputPluginVersion.value,\n        latestVersion: radioValuetoBoolean().version,\n        isNetworkActive: radioValuetoBoolean().network,\n    };\n\n    try {\n        const response = await fetch(\"/plugins\", {\n            method: \"POST\",\n            headers: {\n                \"Content-Type\": \"application/json\",\n            },\n            body: JSON.stringify(pluginData),\n        });\n\n        if (response.ok) {\n            console.log(\"Data sent to server\");\n            window.location.href = response.url; // Perform the redirect\n        } else {\n            const errorData = await response.json();\n            throw errorData;\n        }\n    } catch (e) {\n        console.error(e.error);\n    }\n});\n"
  },
  {
    "type": "python",
    "code": "@tasks.loop(seconds=60)\nasync def check_reminders(self):\n    now = datetime.utcnow()\n    all_reminders = self.backend.filter(ReminderEntry, {})\n    for reminder in all_reminders:\n        reminder_time = reminder['time']\n        if reminder_time <= now:\n            channel = self.bot.get_channel(reminder[\"channel_id\"])\n            user = self.bot.get_user(reminder[\"user_id\"])\n            if reminder[\"location\"] == \"private\":\n                await user.send(reminder[\"text\"])\n            else:\n                await channel.send(\n                    f\"{user.mention}, A reminder for you: {reminder['text']}\"\n                )\n            self.backend.delete(reminder)\n"
  },
  {
    "type": "python",
    "code": "import tkinter as tk\nfrom tkinter import messagebox\n\nclass TicTacToeGUI:\n    def __init__(self, root):\n        self.root = root\n        self.root.title(\"Tic Tac Toe\")\n\n        # Initialize game board, player, etc.\n\n        self.create_widgets()\n\n    def create_widgets(self):\n        # Create buttons for the Tic Tac Toe grid\n        self.buttons = []\n        for i in range(3):\n            row = []\n            for j in range(3):\n                button = tk.Button(self.root, text=\"\", width=10, height=4, command=lambda i=i, j=j: self.on_click(i, j))\n                button.grid(row=i, column=j)\n                row.append(button)\n            self.buttons.append(row)\n\n    def on_click(self, i, j):\n        # Handle button click event\n        pass\n        # Implement game logic here\n\n    # Implement game logic functions (turns, win check, etc.)\n\nif __name__ == \"__main__\":\n    root = tk.Tk()\n    app = TicTacToeGUI(root)\n    root.mainloop()\n"
  },
  {
    "type": "python",
    "code": "import os\nimport glob\nimport argparse\n\ndef generate_cue_files(directory, album, performer, ext=\"m4a\"):\n    current_directory = os.getcwd()\n    search_pattern = os.path.join(current_directory, \"**\", f\"*.{ext}\")\n    files = glob.glob(search_pattern, recursive=True)\n\n    for file in files:\n        txt_file = os.path.splitext(os.path.basename(file))[0] + \".txt\"\n        txt_file_path = os.path.join(current_directory, txt_file)\n        if os.path.exists(txt_file_path):\n            filename = os.path.splitext(os.path.basename(file))[0]\n            description = read_description(txt_file_path)\n            output = make_cue(description, performer, album, filename, ext)\n            cue_file_path = os.path.join(current_directory, f\"{filename}.cue\")\n            save_cue(cue_file_path, output)\n            print(f\"Generated CUE file: {cue_file_path}\")\n\n    print(\"Done!\")\n\n# Rest of the script remains the same...\n"
  },
  {
    "type": "python",
    "code": "import os\nimport shutil\nimport tempfile\nimport unittest\nfrom script import camel_to_snake, rename_file, update_generate_statements\n\nclass ScriptTest(unittest.TestCase):\n    def setUp(self):\n        self.test_dir = tempfile.mkdtemp()\n\n    def tearDown(self):\n        shutil.rmtree(self.test_dir)\n\n    def test_camel_to_snake(self):\n        self.assertEqual(camel_to_snake(\"camelCase\"), \"camel_case\")\n        self.assertEqual(camel_to_snake(\"dcRedirectionPolicy_mock.go\"), \"dc_redirection_policy_mock.go\")\n        self.assertEqual(camel_to_snake(\"nDCHistoryResender_mock.go\"), \"ndc_historyresender_mock.go\")\n\n    def test_rename_file(self):\n        # Create a dummy Go file\n        file_path = os.path.join(self.test_dir, \"testFile.go\")\n        with open(file_path, \"w\") as file:\n            file.write(\"//go:generate mockgen -source TestFile.go -destination TestFile_mock.go\")\n\n        # Rename the file\n        rename_file(file_path)\n\n        # Check if the file is renamed\n        self.assertFalse(os.path.exists(file_path))\n        self.assertTrue(os.path.exists(os.path.join(self.test_dir, \"test_file.go\")))\n\n        # Check if go:generate statement is updated\n        with open(os.path.join(self.test_dir, \"test_file.go\"), \"r\") as file:\n            content = file.read()\n            self.assertIn(\"-source test_file.go -destination test_file_mock.go\", content)\n\n    def test_update_generate_statements(self):\n        # Create a dummy Go file\n        file_path = os.path.join(self.test_dir, \"testFile.go\")\n        with open(file_path, \"w\") as file:\n            file.write(\"//go:generate mockgen -source TestFile.go -destination TestFile_mock.go\")\n\n        # Update go:generate statements\n        update_generate_statements(file_path)\n\n        # Check if go:generate statement is updated\n        with open(file_path, \"r\") as file:\n            content = file.read()\n            self.assertIn(\"-source test_file.go -destination test_file_mock.go\", content)\n\nif __name__ == \"__main__\":\n    unittest.main()\n"
  },
  {
    "type": "javascript",
    "code": "it('should always call initialize on window load', () => {\n    // Define a mock function for the initialize method\n    const mockInitialize = jest.fn();\n    // Define a mock function for initGame\n    const mockInitGame = jest.fn(() => {\n        let game = new Game(false);\n        game.initialize = mockInitialize;\n        game.initialize();\n    });\n\n    // Replace the original methods with the mock functions\n    Game.prototype.initialize = mockInitialize;\n    initGame = mockInitGame;\n\n    // Simulate window load\n    require('./game.js');\n\n    // Check if initGame has been called\n    expect(mockInitGame).toBeCalled();\n\n    // Check if initialize has been called\n    expect(mockInitialize).toBeCalled();\n});\n"
  },
  {
    "type": "javascript",
    "code": "export default class User {\n    constructor(name) {\n        this.name = name || this.getStoredUser();\n    }\n\n    getStoredUser() {\n        let user = localStorage.getItem('user');\n        if (!user) {\n            user = 'admin';\n            localStorage.setItem('user', user);\n        }\n        return user;\n    }\n\n    getPicks() {\n        const picks = JSON.parse(localStorage.getItem(this.name));\n        return picks || {};\n    }\n\n    updatePicks(rikishi) {\n        const picks = this.getPicks();\n        const currentContest = new Date().getMonth();\n        if ([0, 2, 4, 6, 8, 10].includes(currentContest)) {\n            const contestName = new Date().toLocaleString('default', { month: 'long' }) + ' ' + new Date().getFullYear();\n            picks[contestName] = rikishi;\n            localStorage.setItem(this.name, JSON.stringify(picks));\n        }\n    }\n\n    backfillResults(contestName, rikishi) {\n        const picks = this.getPicks();\n        picks[contestName] = rikishi;\n        localStorage.setItem(this.name, JSON.stringify(picks));\n    }\n\n    switchUser(newUser) {\n        localStorage.setItem('user', newUser);\n        this.name = newUser;\n    }\n\n    displayBackfilledResults() {\n        const picks = this.getPicks();\n        const resultsElement = document.querySelector('#backfilledResults');\n\n        // Clear previous results\n        resultsElement.textContent = '';\n\n        // Display each contest result\n        for (const contest in picks) {\n            const rikishi = picks[contest];\n            const resultText = document.createTextNode(contest + ': ' + rikishi);\n            const resultDiv = document.createElement('div');\n            resultDiv.appendChild(resultText);\n            resultsElement.appendChild(resultDiv);\n        }\n    }\n}\n"
  },
  {
    "type": "javascript",
    "code": "const Pick = require('./pick');\n\n// Test case 1\nconst myPick = new Pick('Sumo Wrestler 1');\nconsole.log(myPick.wrestlerName); // Output: Sumo Wrestler 1\n\n// Test case 2\nconst anotherPick = new Pick('Sumo Wrestler 2');\nconsole.log(anotherPick.wrestlerName); // Output: Sumo Wrestler 2\n"
  },
  {
    "type": "javascript",
    "code": "global.$ = jest.fn(() => ({\n    val: jest.fn(() => '1')\n}));\n\nconst { startPlaying } = require('./game');\n\ntest('check if startPlaying is defined and returns expected value', () => {\n    const result = startPlaying();\n    expect(result).toBe(\"You selected: 1\");\n});\n"
  },
  {
    "type": "javascript",
    "code": "const Basho = require('./Basho'); // Update with path to your Basho file\n\ndescribe('Basho Class', () => {\n    let basho;\n    beforeEach(() => {\n        basho = new Basho(1, 1); // First argument is bashoId, second is waveId\n    });\n\n    test('selectWrestler() should add player pick to the basho', () => {\n        basho.selectWrestler('player1', 'wrestler1');\n        expect(basho.getPlayerPick('player1')).toBe('wrestler1');\n    });\n\n    test('selectWrestler() should not overwrite existing pick', () => {\n        basho.selectWrestler('player1', 'wrestler1');\n        basho.selectWrestler('player1', 'wrestler2');\n        expect(basho.getPlayerPick('player1')).toBe('wrestler1');\n    });\n\n    test('changePick() should change player pick', () => {\n        basho.selectWrestler('player1', 'wrestler1');\n        basho.changePick('player1', 'wrestler2');\n        expect(basho.getPlayerPick('player1')).toBe('wrestler2');\n    });\n\n    test('getAllPicks() should return all picks', () => {\n        basho.selectWrestler('player1', 'wrestler1');\n        basho.selectWrestler('player2', 'wrestler2');\n        expect(basho.getAllPicks()).toEqual({\n            player1: 'wrestler1',\n            player2: 'wrestler2'\n        });\n    });\n});\n"
  },
  {
    "type": "javascript",
    "code": "document.body.innerHTML = `\n    <p id=\"user\"></p>\n    <select id=\"rikishi\">\n        <option value=\"1\">Rikishi 1</option>\n        <option value=\"2\">Rikishi 2</option>\n    </select>\n    <input id=\"userSwitch\" type=\"text\">\n    <input id=\"backfillContest\" type=\"text\">\n    <input id=\"backfillRikishi\" type=\"text\">\n    <div id=\"backfilledResults\"></div>\n`;\n"
  },
  {
    "type": "javascript",
    "code": "if (typeof window !== 'undefined') {\n    window.game = new Game(true);\n}\n"
  },
  {
    "type": "javascript",
    "code": "// ...\n\nconst { startPlaying, switchUser, backfillResults, initialize } = require('./game');\n\nbeforeEach(() => {\n    localStorage.clear(); // clear localStorage before each test\n    // Reset the HTML body before each test\n    document.body.innerHTML = `\n        <p id=\"user\"></p>\n        <select id=\"rikishi\">\n            <option value=\"1\">Rikishi 1</option>\n            <option value=\"2\">Rikishi 2</option>\n        </select>\n        <input id=\"userSwitch\" type=\"text\">\n        <input id=\"backfillContest\" type=\"text\">\n        <input id=\"backfillRikishi\" type=\"text\">\n    `;\n    initialize(); // Call the initialization function here\n});\n\n// ...\n"
  },
  {
    "type": "javascript",
    "code": "const Game = require('./game.js');\n\nlet game;\n\nbeforeEach(() => {\n    //... setup logic\n    game = new Game();\n});\n"
  },
  {
    "type": "python",
    "code": "import boto3\nfrom datetime import datetime\n\ndef lambda_handler(event, context):\n    s3_client = boto3.client('s3')\n    bucket_name = 'your-backup-bucket-name'\n    \n    # Get today's date in the format that matches your file naming\n    today = datetime.today().strftime('%Y-%m-%d')\n    \n    # List objects with today's date\n    response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=today)\n    \n    if 'Contents' in response:\n        # Sort by name or other criteria and select one to retain\n        backups_today = sorted(response['Contents'], key=lambda x: x['Key'])\n        backup_to_retain = backups_today[0]  # Retain the first backup, modify as needed\n        \n        # Update tags for the retained backup\n        s3_client.put_object_tagging(\n            Bucket=bucket_name,\n            Key=backup_to_retain['Key'],\n            Tagging={\n                'TagSet': [\n                    {\n                        'Key': 'ToBeDeleted',\n                        'Value': 'False'\n                    }\n                ]\n            }\n        )\n"
  },
  {
    "type": "javascript",
    "code": "// script.js\ndocument.addEventListener(\"DOMContentLoaded\", function() {\n    // Your JavaScript code goes here\n});\n"
  },
  {
    "type": "javascript",
    "code": "// \uc774\ubca4\ud2b8 \ub9ac\uc2a4\ub108 \ud568\uc218 \uc815\uc758\nfunction visibilityChangeListener(ws_url, id, navigate) {\n    return () => {\n        handleVisibilityChange(ws_url, id, navigate).catch(error =>\n            console.error(error)\n        );\n    };\n}\n\n// \uc774\ubca4\ud2b8 \ub9ac\uc2a4\ub108 \ucd94\uac00\nconst listener = visibilityChangeListener(ws_url, id, navigate);\ndocument.addEventListener('visibilitychange', listener);\n\n// \uc774\ubca4\ud2b8 \ub9ac\uc2a4\ub108 \uc81c\uac70\ndocument.removeEventListener('visibilitychange', listener);\n"
  },
  {
    "type": "javascript",
    "code": "expect(actual).toBe(expected);\n"
  },
  {
    "type": "python",
    "code": "if __name__ == '__main__':\n    app.run(debug=True)\n"
  },
  {
    "type": "python",
    "code": "import unittest\nfrom freezegun import freeze_time\nfrom your_module import YourClass  # assuming the method is part of a class\n\nclass TestYourClass(unittest.TestCase):\n\n    @freeze_time(\"2023-10-10\")\n    def test_date_dim_row(self):\n        instance = YourClass()\n        expected_row = {\n            \"date_key\" : \"2023-10-10\",\n            \"year\": 2023,\n            \"month_key\": 10,\n            \"day\": 10,\n            \"day_key\": 2,\n            \"week_number\": 41,\n            \"week_end\": \"2023-10-14\",\n            \"month_end\": \"2023-10-31\",\n        }\n        self.assertEqual([expected_row], instance.date_dim_row())\n\n# If you're running this directly\nif __name__ == '__main__':\n    unittest.main()\n"
  },
  {
    "type": "ruby",
    "code": "gem 'fastlane', '~> 2.180.0'\n"
  },
  {
    "type": "python",
    "code": "import logging\n\n# Configure the root logger to display messages at or above the DEBUG level\nlogging.basicConfig(level=logging.DEBUG)\n"
  },
  {
    "type": "python",
    "code": "def max_sequence(arr):\n    max_sum = 0\n    current_sum = 0\n    \n    for num in arr:\n        current_sum = max(num, current_sum + num)\n        max_sum = max(max_sum, current_sum)\n    \n    return max_sum\n\n# Test your function\nresult = max_sequence([-2, 1, -3, 4, -1, 2, 1, -5, 4])\nprint(result)  # Output should be 6\n"
  },
  {
    "type": "python",
    "code": "from django.core.paginator import Paginator\nfrom django.shortcuts import render\n\ndef get_more_movies(request):\n    page_number = int(request.GET.get(\"page\", 1))\n    movies_per_page = NUMBER_MOVIES_PER_PAGE\n\n    movies = Movie.objects.all()\n    paginator = Paginator(movies, movies_per_page)\n\n    page = paginator.get_page(page_number)\n    movies = page.object_list\n\n    context = {\n        'movies': movies,\n        'next_page': page_number + 1 if page.has_next() else None,\n    }\n    return render(request, 'movies/_movies.html', context)\n"
  },
  {
    "type": "python",
    "code": "import requests\n\n# Jira API endpoint to check permissions\napi_url = 'https://your-jira-url.com/rest/api/2/mypermissions'\n\n# Replace 'username' and 'password' with your Jira credentials\nauth = ('username', 'password')\n\n# Specify the project key associated with the board\nproject_key = 'YOUR_PROJECT_KEY'\n\n# Send a GET request to the API endpoint\nresponse = requests.get(api_url, auth=auth, params={'projectKey': project_key})\n\nif response.status_code == 200:\n    permissions = response.json().get('permissions', {})\n    create_issue_permission = permissions.get('CREATE_ISSUE', False)\n\n    if create_issue_permission:\n        print(f\"You have permissions to create an issue on project {project_key}.\")\n    else:\n        print(f\"You do not have permissions to create an issue on project {project_key}.\")\nelse:\n    print(\"Failed to retrieve permissions from the Jira API.\")\n"
  },
  {
    "type": "python",
    "code": "# Make sure to replace `...` with the actual code snippet\n# Start Models\n...\n# End Models\n"
  },
  {
    "type": "java",
    "code": "public static void checkForBlockChange(BlockPos pos, IBlockState blockState) {\n    BlockData oldBlockData = null;\n\n    // Create a copy of the key set of 'blocksClicked'\n    Set<Long> keysCopy = new HashSet<>(blocksClicked.keySet());\n\n    for (Long key : keysCopy) {\n        BlockData value = blocksClicked.get(key);\n\n        if (value.blockPos.equals(pos)) {\n            oldBlockData = value;\n            blocksClicked.remove(key); // Modify the original map safely\n        }\n    }\n\n    if (oldBlockData != null) {\n        IBlockState oldState = oldBlockData.blockState;\n        if ((oldState.getBlock() == Blocks.log || oldState.getBlock() == Blocks.log2) &&\n            blockState.getBlock() == Blocks.air) {\n            onBlockMined();\n        }\n    }\n}\n"
  },
  {
    "type": "python",
    "code": "def bar(obj: T) -> T:\n    return obj.foo()\n"
  },
  {
    "type": "javascript",
    "code": "// ==UserScript==\n// @name         My Userscript\n// @version      1.0\n// @description  Example userscript with UTF-8 encoding\n// @match        https://example.com/*\n// @charset      UTF-8\n// ==/UserScript==\n\n// Your code goes here\n"
  },
  {
    "type": "python",
    "code": "if isinstance(s, int) and tensor_found: [tensor_found[i] for i in range(len(tensor_found)) if tensor_found[i][0] > i][0][0] -= 1\n"
  },
  {
    "type": "python",
    "code": "import pandas as pd\n\n# Assuming you have a DataFrame named 'df' with a 'date' column\n\n# Convert the 'date' column to datetime type if it's not already\ndf['date'] = pd.to_datetime(df['date'])\n\n# Group the DataFrame by the 'date' column\ngrouped = df.groupby(pd.Grouper(key='date', freq='D'))\n\n# Iterate over the groups and create individual DataFrames\nfor group_name, group_data in grouped:\n    # 'group_name' is the date value\n    # 'group_data' is the corresponding data for that date\n    \n    # Create a new DataFrame for each group\n    new_df = pd.DataFrame(group_data)\n    \n    # Perform any additional operations or analysis on the new DataFrame\n    \n    # Print the new DataFrame for demonstration purposes\n    print(f\"DataFrame for {group_name}:\")\n    print(new_df)\n"
  },
  {
    "type": "java",
    "code": "public class EntityA {\n    // \uae30\ubcf8 \uc0dd\uc131\uc790\n    public EntityA() {\n        // ...\n    }\n\n    // \uc0dd\uc131\uc790\n    public EntityA(Long id, String name) {\n        // ...\n    }\n\n    // Getters and setters...\n}\n"
  },
  {
    "type": "javascript",
    "code": "handleWatchFileChanges(filePath) {\n  try {\n    let isWatching = true; // \u76e3\u8996\u30d5\u30e9\u30b0\u3092\u8ffd\u52a0\n\n    fs.watch(filePath, eventType => {\n      if (eventType === \"change\" && isWatching) { // \u76e3\u8996\u30d5\u30e9\u30b0\u304c\u6709\u52b9\u306a\u5834\u5408\u306e\u307f\u51e6\u7406\u3092\u5b9f\u884c\n        isWatching = false; // \u76e3\u8996\u30d5\u30e9\u30b0\u3092\u7121\u52b9\u5316\n        console.log(\"File changed\");\n        this.handleLoad(filePath, \"utf8\");\n        setTimeout(() => {\n          isWatching = true; // \u4e00\u5b9a\u6642\u9593\u5f8c\u306b\u76e3\u8996\u30d5\u30e9\u30b0\u3092\u518d\u5ea6\u6709\u52b9\u5316\n        }, 1000); // 1\u79d2\u5f8c\u306b\u518d\u5ea6\u76e3\u8996\u30d5\u30e9\u30b0\u3092\u6709\u52b9\u5316\u3059\u308b\u4f8b\n      }\n    });\n  } catch (error) {\n    this.Err.errorMain(error);\n  }\n}\n"
  },
  {
    "type": "javascript",
    "code": "const [filterControls, setFilterControls] = useState<{category: number, format: number}>({category: -1, format: -1});\n"
  },
  {
    "type": "python",
    "code": "import re\n\ndef identify_string(string):\n    # Regular expression patterns for Twitch login names and StreamElements account IDs\n    twitch_pattern = r\"^[A-Za-z0-9_]{4,25}$\"\n    streamelements_pattern = r\"^[a-fA-F0-9]{24}$\"\n\n    if re.match(twitch_pattern, string):\n        return \"Twitch login name\"\n    elif re.match(streamelements_pattern, string):\n        return \"StreamElements Account ID\"\n    else:\n        return \"Unknown\"\n\n# Example usage\nstring1 = \"mytwitchusername123\"\nstring2 = \"5eb63bbbe01eeed093cb22bb8f5acdc3\"\nstring3 = \"invalid_string\"\n\nprint(identify_string(string1))  # Output: Twitch login name\nprint(identify_string(string2))  # Output: StreamElements Account ID\nprint(identify_string(string3))  # Output: Unknown\n"
  },
  {
    "type": "java",
    "code": "Logger logger = LogManager.getLogger();\nlogger.atInfo().withKeyValue(\"userId\", \"12345\").log(\"User logged in\");\n"
  },
  {
    "type": "ruby",
    "code": "https://api.github.com/repos/ubiquity/ubiquibot/pulls/759.diff\n"
  },
  {
    "type": "javascript",
    "code": "import {CompositeLayer, SolidPolygonLayer} from '@deck.gl/layers';\nimport {getRadiusInPixel, toRadians} from './utils';  // You need to implement these utility functions\n\nclass PieChartLayer extends CompositeLayer {\n  renderLayers() {\n    const {data, radius, getColor} = this.props;\n    \n    const pieSlices = data.reduce((acc, d) => {\n      const [longitude, latitude] = d.position;\n      const values = d.values;\n      const total = values.reduce((sum, val) => sum + val, 0);\n      let startAngle = 0;\n\n      values.forEach((value, i) => {\n        const percentage = value / total;\n        const angle = percentage * 360;\n        const endAngle = startAngle + angle;\n        const radiusInPixels = getRadiusInPixel(radius, latitude);\n\n        const slice = {\n          ...d,\n          startAngle: toRadians(startAngle),\n          endAngle: toRadians(endAngle),\n          radius: radiusInPixels,\n          color: getColor(d, i)\n        };\n\n        acc.push(slice);\n        startAngle = endAngle;\n      });\n\n      return acc;\n    }, []);\n\n    return new SolidPolygonLayer(this.getSubLayerProps({\n      id: 'pie-slices',\n      data: pieSlices,\n      getPolygon: d => getArc(d.startAngle, d.endAngle, d.radius),\n      getFillColor: d => d.color,\n      getElevation: d => 1000  // You can customize the elevation here\n    }));\n  }\n}\n\n// You need to implement this function to convert the start and end angles\n// and the radius into a polygon that represents a slice of the pie.\nfunction getArc(startAngle, endAngle, radius) {\n  // TODO: Implement this function\n}\n\nPieChartLayer.layerName = 'PieChartLayer';\n"
  },
  {
    "type": "python",
    "code": "import click\nimport frontmatter\nfrom click_default_group import DefaultGroup\nfrom dotenv import dotenv_values, set_key\n\n__author__ = \"Jeff Triplett\"\n__email__ = \"jeff.triplett@gmail.com\"\n__version__ = \"2023.3.1\"\n\n\ndef validate_extra_context(ctx, param, value):\n    \"\"\"Validate extra context.\"\"\"\n    for key in value:\n        if \"=\" not in key:\n            raise click.BadParameter(\n                \"EXTRA_CONTEXT should contain items of the form key=value; \"\n                \"'{}' doesn't match that form\".format(key)\n            )\n\n    return dict(key.lstrip(\"-\").split(\"=\", 1) for key in value) or None\n\n\n@click.group(cls=DefaultGroup, default=\"main\", default_if_no_args=True)\n@click.pass_context\ndef cli(context):\n    pass\n\n\n@cli.command(\n    context_settings=dict(\n        ignore_unknown_options=True,\n    )\n)\n@click.version_option(prog_name=\"frontmatter-cli\", version=__version__)\n@click.argument(\"extra_context\", nargs=-1, callback=validate_extra_context)\n@click.argument(\"input\", type=click.File(\"rb\"), default=\"-\")\n@click.argument(\"output\", type=click.File(\"wb\"), default=\"-\")\ndef main(input, output, extra_context):\n    chunk = input.read()\n    post = frontmatter.loads(chunk)\n\n    if extra_context:\n        for key, value in extra_context.items():\n            set_key(post.metadata, key, value)\n\n    frontmatter.dump(post, output)\n\n\nif __name__ == \"__main__\":\n    cli()\n"
  },
  {
    "type": "java",
    "code": "@Transactional\npublic void saveEntity(Entity entity) {\n    try {\n        // Repository save operation\n        repository.save(entity);\n    } catch (Exception ex) {\n        // Log the exception or perform error handling\n        throw ex; // or throw a new exception\n    }\n}\n"
  },
  {
    "type": "python",
    "code": "from pydub import AudioSegment\n\n# Load the first WAV file\ncombined = AudioSegment.from_wav(\"file1.wav\")\n\n# Concatenate other WAV files\nother_files = [\"file2.wav\", \"file3.wav\"]  # Add as many as needed\nfor file in other_files:\n    sound = AudioSegment.from_wav(file)\n    combined += sound\n\n# Export the combined audio\ncombined.export(\"combined.wav\", format=\"wav\")\n"
  },
  {
    "type": "java",
    "code": "protected List<Point> getPointsInRange(int start, int end) {\n    int locX = getLocalX();\n    int locY = getLocalY();\n    int height = methods.calc.tileHeight(locX, locY);\n    Polygon[] triangles = this.getTriangles();\n    List<Point> points = new ArrayList<>();\n\n    for (int i = start; i < end && i < triangles.length; i++) {\n        for (int n = 0; n < triangles[i].npoints; n++) {\n            points.add(new Point(triangles[i].xpoints[n], triangles[i].ypoints[n]));\n        }\n    }\n    return points;\n}\n"
  },
  {
    "type": "c++",
    "code": "#include <iostream>\n#include <sstream>\n#include <ctime>\n#include <esp_system.h>\n#include <nvs_flash.h>\n#include <nvs.h>\n\nint main() {\n  // Initialize NVS\n  esp_err_t err = nvs_flash_init();\n  if (err == ESP_ERR_NVS_NO_FREE_PAGES || err == ESP_ERR_NVS_NEW_VERSION_FOUND) {\n    // NVS partition was truncated and needs to be erased\n    ESP_ERROR_CHECK(nvs_flash_erase());\n    err = nvs_flash_init();\n  }\n  ESP_ERROR_CHECK(err);\n\n  // Open NVS namespace for storing previous timestamp and DST flag\n  nvs_handle nvs;\n  err = nvs_open(\"timestamp\", NVS_READWRITE, &nvs);\n  if (err != ESP_OK) {\n    std::cout << \"Error opening NVS: \" << esp_err_to_name(err) << std::endl;\n    return 1;\n  }\n\n  // Input timestamp string\n  std::string timestamp_str = \"231031020000\"; // YYMMDDhhmmss format\n\n  // Parse input timestamp string\n  std::tm timestamp_tm = {};\n  std::stringstream ss(timestamp_str);\n  ss >> std::get_time(&timestamp_tm, \"%y%m%d%H%M%S\");\n\n  // Check if current timestamp occurs between 2:00 AM and 3:00 AM\n  bool ambiguous_time = timestamp_tm.tm_hour == 2 && timestamp_tm.tm_min == 0 && timestamp_tm.tm_sec == 0;\n\n  // Load previous timestamp and DST flag from NVS\n  std::time_t prev_timestamp_unix = 0;\n  nvs_get_i64(nvs, \"timestamp_unix\", &prev_timestamp_unix);\n  int prev_dst_flag = -1;\n  nvs_get_i32(nvs, \"dst_flag\", &prev_dst_flag);\n\n  if (prev_dst_flag == -1) {\n    // No previous DST flag, let mktime determine DST flag for current timestamp\n    timestamp_tm.tm_isdst = -1;\n  } else if (!ambiguous_time) {\n    // Current timestamp does not occur between 2:00 AM and 3:00 AM, use previous DST flag\n    timestamp_tm.tm_isdst = prev_dst_flag;\n  } else if (prev_timestamp_unix == 0) {\n    // No previous timestamp, assume current timestamp is in standard time\n    timestamp_tm.tm_isdst = 0;\n  } else {\n    // Determine DST flag based on previous timestamp and current timestamp\n    std::tm prev_timestamp_tm = *std::localtime(&prev_timestamp_unix);\n    if (prev_timestamp_tm.tm_hour < 2 || (prev_timestamp_tm.tm_hour == 2 && prev_timestamp_tm.tm_min < 0)) {\n      // Previous timestamp occurred before DST transition time (2:00 AM)\n      timestamp_tm.tm_isdst = 0; // assume current timestamp is in standard time\n    } else if (prev_timestamp_tm.tm_hour > 3 || (prev_timestamp_tm.tm_hour == 3 && prev_timestamp_tm.tm_min >= 0)) {\n      // Previous timestamp occurred after DST transition time (3:00 AM)\n      timestamp_tm.tm_isdst = 1; // assume current timestamp is in DST\n    } else {\n      // Previous timestamp occurred during the hour that occurs twice due to the DST transition\n      timestamp_tm.tm_isdst = prev_dst_flag; // use previous DST flag\n    }\n  }\n\n  // Convert local time to Unix timestamp\n  std::time_t timestamp_unix = std::mktime\n"
  },
  {
    "type": "javascript",
    "code": "Cypress.Commands.add('getRandomFixture', () => {\n    return cy.readFile('cypress/fixtures/usedTorrents.json').then((usedTorrents) => {\n        return cy.readFile('cypress/fixtures/torrents.json').then((allTorrents) => {\n            const unusedTorrents = allTorrents.filter((torrent) => !usedTorrents.includes(torrent));\n\n            // If there are no unused torrents, reset the used torrents list\n            if (unusedTorrents.length === 0) {\n                cy.writeFile('cypress/fixtures/usedTorrents.json', []);\n                unusedTorrents = allTorrents;\n            }\n\n            const selectedTorrent = unusedTorrents[Math.floor(Math.random() * unusedTorrents.length)];\n\n            // Add the selected torrent to the used torrents list\n            usedTorrents.push(selectedTorrent);\n            cy.writeFile('cypress/fixtures/usedTorrents.json', usedTorrents);\n\n            return cy.fixture(`torrents/${selectedTorrent}`);\n        });\n    });\n});\n"
  },
  {
    "type": "python",
    "code": "import boto3\nfrom botocore.client import Config\n\n# Configure the endpoint URLs for different services\ns3_endpoint_url = 'http://localhost:4572'\nsqs_endpoint_url = 'http://localhost:4576'\n\n# Create custom session objects with different endpoint URLs\ns3_session = boto3.session.Session()\nsqs_session = boto3.session.Session()\n\ns3_session.resource('s3').meta.client.meta.events.register(\n    'choose-signer.s3.*', boto3.session.Session().get_default_s3_signer)\ns3_session.client('s3').meta.events.register(\n    'choose-signer.s3.*', boto3.session.Session().get_default_s3_signer)\ns3_session.client('s3').meta.events.register(\n    'choose-signer.s3.*', boto3.session.Session().get_default_s3_signer)\n\nsqs_session.resource('sqs').meta.client.meta.events.register(\n    'choose-signer.sqs.*', boto3.session.Session().get_default_s3_signer)\nsqs_session.client('sqs').meta.events.register(\n    'choose-signer.sqs.*', boto3.session.Session().get_default_s3_signer)\nsqs_session.client('sqs').meta.events.register(\n    'choose-signer.sqs.*', boto3.session.Session().get_default_s3_signer)\n\ns3_session.client('s3').meta.events.register(\n    'before-sign.s3', boto3.session.Session().inject_endpoint_url)\nsqs_session.client('sqs').meta.events.register(\n    'before-sign.s3', boto3.session.Session().inject_endpoint_url)\n\n# Set the custom sessions as default session factories\nboto3.setup_default_session(\n    region_name='us-east-1', \n    botocore_session=s3_session,\n    session=boto3.DEFAULT_SESSION)\n\nboto3.setup_default_session(\n    region_name='us-east-1', \n    botocore_session=sqs_session,\n    session=boto3.DEFAULT_SESSION)\n\n# Now all subsequent client/resource creation will use the registered sessions\ns3_client = boto3.client('s3')\nsqs_resource = boto3.resource('sqs')\n\n# Use the S3 client and SQS resource with the custom endpoint URLs\ns3_client.list_buckets()\nsqs_resource.list_queues()\n"
  },
  {
    "type": "ruby",
    "code": "# Get all comments from the responses table\ncomments = Response.pluck(:comment)\n\n# Define regex pattern for @ followed by digits\npattern = /@(\\d+)/\n\n# Extract all user ID's into an array\nuser_ids = comments.map { |comment| comment.scan(pattern) }.flatten\n\n# Convert all elements to integer (as they will be strings after the regex)\nuser_ids = user_ids.map(&:to_i)\n"
  },
  {
    "type": "javascript",
    "code": "const pool = new Pool({\n  // ... other parameters ...\n  ssl: {\n    ca: fs.readFileSync('/path/to/rds-ca-cert.pem').toString(),\n    rejectUnauthorized: true\n  }\n});\n"
  },
  {
    "type": "javascript",
    "code": "document.getElementById(\"downloadButton\").addEventListener(\"click\", function () {\n    window.location.href = \"download.php\";\n});\n"
  },
  {
    "type": "java",
    "code": "import org.junit.jupiter.api.*;\nimport org.testcontainers.containers.GenericContainer;\nimport org.testcontainers.junit.jupiter.Container;\nimport org.testcontainers.junit.jupiter.Testcontainers;\n\n@Testcontainers\npublic class MyContainerizedTest extends ContainerExecutionExtensionSupport {\n\n    @Container\n    private static final GenericContainer<?> container = new GenericContainer<>(\"my-container-image:latest\");\n\n    @BeforeEach\n    public void setup() {\n        container.start();\n        // Additional setup if needed\n    }\n\n    @AfterEach\n    public void teardown() {\n        // Additional teardown if needed\n        container.stop();\n    }\n\n    @Test\n    public void myTest() {\n        // Access container services or interact with the container as required for testing\n    }\n}\n"
  },
  {
    "type": "javascript",
    "code": "document.addEventListener(\"DOMContentLoaded\", function () {\n    const hamburger = document.querySelector(\".hamburger\");\n    const menu = document.querySelector(\".container\");\n\n    hamburger.addEventListener(\"click\", function () {\n        menu.style.display = menu.style.display === \"none\" ? \"block\" : \"none\";\n    });\n});\n"
  },
  {
    "type": "javascript",
    "code": "const express = require('express');\nconst bodyParser = require('body-parser');\nconst { Gateway, Wallets } = require('fabric-network');\nconst AlertContract = require('./alert-contract'); // Import chaincode\n\nconst app = express();\napp.use(bodyParser.json());\n\nconst ccpPath = './path-to-your-connection-profile.json'; // \u0110i\u1ec1u ch\u1ec9nh \u0111\u01b0\u1eddng d\u1eabn \u0111\u1ebfn connection profile c\u1ee7a b\u1ea1n\nconst walletPath = './path-to-your-wallet'; // \u0110i\u1ec1u ch\u1ec9nh \u0111\u01b0\u1eddng d\u1eabn \u0111\u1ebfn wallet c\u1ee7a b\u1ea1n\n\napp.post('/addAlert', async (req, res) => {\n    try {\n        const { alertID, description, timestamp } = req.body;\n        \n        const gateway = new Gateway();\n        const wallet = await Wallets.newFileSystemWallet(walletPath);\n\n        await gateway.connect(ccpPath, {\n            wallet,\n            identity: 'user1', // \u0110i\u1ec1u ch\u1ec9nh danh t\u00ednh c\u1ee7a b\u1ea1n t\u1ea1i \u0111\u00e2y\n            discovery: { enabled: true, asLocalhost: true },\n        });\n\n        const network = await gateway.getNetwork('mychannel'); // \u0110i\u1ec1u ch\u1ec9nh t\u00ean k\u00eanh c\u1ee7a b\u1ea1n\n        const contract = network.getContract('alert-contract'); // \u0110i\u1ec1u ch\u1ec9nh t\u00ean contract c\u1ee7a b\u1ea1n\n\n        await contract.submitTransaction('addAlert', alertID, description, timestamp);\n\n        res.send('S\u1ef1 ki\u1ec7n c\u1ea3nh b\u00e1o \u0111\u00e3 \u0111\u01b0\u1ee3c th\u00eam th\u00e0nh c\u00f4ng v\u00e0o blockchain');\n    } catch (error) {\n        console.error(`L\u1ed7i: ${error}`);\n        res.status(500).send(`L\u1ed7i: ${error.message}`);\n    }\n});\n\napp.listen(3000, () => {\n    console.log('Server \u0111ang l\u1eafng nghe t\u1ea1i c\u1ed5ng 3000');\n});\n"
  },
  {
    "type": "javascript",
    "code": "// Store the current URL without parameters as the key\nvar currentURLWithoutParams = window.location.href.split('?')[0]; // Remove query parameters\nvar currentURLWithParams = window.location.href; // Full URL with parameters\nlocalStorage.setItem(currentURLWithoutParams, currentURLWithParams);\n\n// Retrieve the URL with parameters when viewing the current URL without parameters\nvar storedURLWithParams = localStorage.getItem(currentURLWithoutParams);\n\n// You can now use 'storedURLWithParams' for your purposes.\n"
  },
  {
    "type": "javascript",
    "code": "const express = require('express');\nconst apiRoutes = require('./routes/apiRoutes');\n\nconst app = express();\nconst port = 3001;\n\napp.use('/api', apiRoutes);\napp.listen(port, () => {\n  console.log(`Listening on port ${port}`);\n});\n"
  },
  {
    "type": "python",
    "code": "if \"--elven-cloak\" in sys.argv:\n    print(\"Running in stealth mode. The elves would be proud!\")\n"
  },
  {
    "type": "java",
    "code": "package org.example.rpsarena;\n\nimport java.util.Random;\n\npublic class Game {\n    private MainActivity activity;\n    private Player player;\n    private Player opponent;\n    private GameLogic gameLogic;\n\n    public Game(MainActivity activity) {\n        this.activity = activity;\n        this.gameLogic = new GameLogic();\n        setupGame();\n    }\n\n    private void setupGame() {\n        player = new Player(\"Player 1\");\n        opponent = new Player(\"Player 2\");\n        player.setOpponent(opponent);\n        opponent.setOpponent(player);\n        updateScores();\n    }\n\n    public void onMoveSelected(String move) {\n        if (move.equalsIgnoreCase(\"exit\")) {\n            exitGame();\n        } else {\n            Moves playerMove = convertToMove(move);\n            if (playerMove == null) {\n                activity.updateMovesText(\"Invalid move. Please try again.\");\n            } else {\n                Moves opponentMove = generateOpponentMove();\n                String result = gameLogic.determineWinner(playerMove, opponentMove);\n                updateScores(result);\n                activity.updateMovesText(\"Your Move: \" + move + \"\\nOpponent Move: \" + opponentMove);\n            }\n        }\n    }\n\n    private Moves convertToMove(String input) {\n        try {\n            return Moves.valueOf(input.toUpperCase());\n        } catch (IllegalArgumentException e) {\n            return null;\n        }\n    }\n\n    private Moves generateOpponentMove() {\n        Moves[] moves = Moves.values();\n        Random random = new Random();\n        return moves[random.nextInt(moves.length)];\n    }\n\n    private void updateScores(String result) {\n        if (result.equals(\"WIN\")) {\n            player.incrementPoints();\n            activity.updateScores(player.getPlayerPoints(), opponent.getPlayerPoints());\n        } else if (result.equals(\"LOSS\")) {\n            opponent.incrementPoints();\n            activity.updateScores(player.getPlayerPoints(), opponent.getPlayerPoints());\n        }\n    }\n\n    private void updateScores() {\n        activity.updateScores(player.getPlayerPoints(), opponent.getPlayerPoints());\n    }\n\n    public void exitGame() {\n        // Any cleanup or additional actions required on game exit\n    }\n}\n"
  },
  {
    "type": "python",
    "code": "from scapy.all import *\n\ndef send_dns_packet(domain, secret_payload):\n    # Replace these values with the appropriate destination IP and port\n    destination_ip = \"Destination_IP_Address\"\n    destination_port = 53\n\n    # Craft the DNS packet with the secret payload\n    dns_packet = IP(dst=destination_ip)/UDP(dport=destination_port)/DNS(rd=1, qd=DNSQR(qname=domain, qtype=\"A\")/secret_payload)\n\n    # Send the DNS packet\n    send(dns_packet)\n\nif __name__ == \"__main__\":\n    domain_name = \"example.com\"\n    secret_data = \"This is a secret payload!\"\n\n    send_dns_packet(domain_name, secret_data)\n"
  },
  {
    "type": "c",
    "code": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <unistd.h>\n#include <arpa/inet.h>\n\n#define SERVER_IP \"169.254.14.229\" // Replace with the server's IP address\n#define PORT 8080\n#define BUFFER_SIZE sizeof(int)\n\nint main() {\n    int client_socket;\n    struct sockaddr_in server_addr;\n\n    // Create socket\n    if ((client_socket = socket(AF_INET, SOCK_DGRAM, 0)) < 0) {\n        perror(\"socket creation failed\");\n        exit(EXIT_FAILURE);\n    }\n\n    memset(&server_addr, 0, sizeof(server_addr));\n\n    // Configure server address\n    server_addr.sin_family = AF_INET;\n    server_addr.sin_port = htons(PORT);\n    if (inet_pton(AF_INET, SERVER_IP, &server_addr.sin_addr) <= 0) {\n        perror(\"Invalid address/ Address not supported\");\n        exit(EXIT_FAILURE);\n    }\n\n    int number;\n\n    while (1) {\n        // Send number to server\n        printf(\"Client (You): \");\n        scanf(\"%d\", &number);\n        sendto(client_socket, &number, sizeof(int), 0,\n               (const struct sockaddr *)&server_addr, sizeof(server_addr));\n\n        // Receive number from server\n        recvfrom(client_socket, &number, sizeof(int), 0, NULL, NULL);\n        printf(\"Server: %d\\n\", number);\n    }\n\n    close(client_socket);\n    return 0;\n}\n"
  },
  {
    "type": "python",
    "code": "def create_ui(interface: gr.Blocks, unrelated_tabs, tabname):\n    from modules.ui import switch_values_symbol\n\n    ui = ExtraNetworksUi()\n    ui.pages = []\n    ui.pages_contents = []\n    ui.user_metadata_editors = []\n    ui.stored_extra_pages = pages_in_preferred_order(extra_pages.copy())\n    ui.tabname = tabname\n\n    related_tabs = []\n\n    for page in ui.stored_extra_pages:\n        with gr.Tab(page.title, id=page.id_page) as tab:\n            elem_id = f\"{tabname}_{page.id_page}_cards_html\"\n            page_elem = gr.HTML('Loading...', elem_id=elem_id)\n            ui.pages.append(page_elem)\n\n            page_elem.change(fn=lambda: None, _js='function(){applyExtraNetworkFilter(' + quote_js(tabname) + '); return []}', inputs=[], outputs=[])\n\n            editor = page.create_user_metadata_editor(ui, tabname)\n            editor.create_ui()\n            ui.user_metadata_editors.append(editor)\n\n            related_tabs.append(tab)\n\n    edit_search = gr.Textbox('', show_label=False, elem_id=tabname+\"_extra_search\", elem_classes=\"search\", placeholder=\"Search...\", visible=False, interactive=True)\n    dropdown_sort = gr.Dropdown(choices=['Default Sort', 'Date Created', 'Date Modified', 'Name'], value='Default Sort', elem_id=tabname+\"_extra_sort\", elem_classes=\"sort\", multiselect=False, visible=False, show_label=False, interactive=True, label=tabname+\"_extra_sort_order\")\n    button_sortorder = ToolButton(switch_values_symbol, elem_id=tabname+\"_extra_sortorder\", elem_classes=\"sortorder\", visible=False)\n    button_refresh = gr.Button('Refresh', elem_id=tabname+\"_extra_refresh\", visible=False)\n    checkbox_show_dirs = gr.Checkbox(True, label='Show dirs', elem_id=tabname+\"_extra_show_dirs\", elem_classes=\"show-dirs\", visible=False)\n\n    ui.button_save_preview = gr.Button('Save preview', elem_id=tabname+\"_save_preview\", visible=False)\n    ui.preview_target_filename = gr.Textbox('Preview save filename', elem_id=tabname+\"_preview_filename\", visible=False)\n\n    # Replace unrelated_tabs with your actual UI components that are unrelated to extra networks UI.\n    for tab in unrelated_tabs:\n        tab.select(fn=lambda: [gr.update(visible=False) for _ in range(5)], inputs=[], outputs=[edit_search, dropdown_sort, button_sortorder, button_refresh, checkbox_show_dirs], show_progress=False)\n\n    for tab in related_tabs:\n        tab.select(fn=lambda: [gr.update(visible=True) for _ in range(5)], inputs=[], outputs=[edit_search, dropdown_sort, button_sortorder, button_refresh, checkbox_show_dirs], show_progress=False)\n\n    def pages_html():\n        if not ui.pages_contents:\n            return refresh()\n\n        return ui.pages_contents\n\n    def refresh():\n        for pg in ui.stored_extra_pages:\n            pg.refresh()\n\n        ui.pages_contents = [pg.create_html(ui.tabname) for pg in ui.stored_extra_pages]\n\n        return ui.pages_contents\n\n    interface.load(fn=pages_html, inputs=[], outputs=[*ui.pages])\n    button_refresh.click(fn=refresh, inputs=[], outputs=ui.pages)\n\n    return ui\n"
  },
  {
    "type": "python",
    "code": "def generate_rap_line(prompt):\n    response = openai.ChatCompletion.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[\n            {\"role\": \"system\", \"content\": \"You are a rapper composer that uses the bip39 wordlist to rhyme.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n    )\n\n    rap_line = response['choices'][0]['message']['content']\n    # Find a rhyme from the bip39 wordlist\n    rhyme = find_rhyme(rap_line, bip39_wordlist)\n    rap_line += \" \" + rhyme\n\n    return rap_line\n"
  },
  {
    "type": "java",
    "code": "void executeConcurrentRequests100Times()\n"
  },
  {
    "type": "python",
    "code": "from flask import Flask, render_template, request, jsonify\nimport os\nimport cv2\nimport numpy as np\nimport tensorflow as tf\n\napp = Flask(__name__)\n\n# Load the pre-trained model\nmodel = tf.keras.models.load_model('digit_recognizer_model.h5')\n\n@app.route('/')\ndef index():\n    return render_template('index.html')\n\n@app.route('/upload', methods=['POST'])\ndef upload_file():\n    if request.method == 'POST':\n        # Check if the request contains a file\n        if 'file' not in request.files:\n            return 'No file part'\n\n        file = request.files['file']\n\n        # If the user does not select a file, the browser may submit an empty part without a filename\n        if file.filename == '':\n            return 'No selected file'\n\n        # Save the uploaded file to a specific location (you can customize this)\n        file.save('uploads/' + file.filename)\n\n        # Read the image using OpenCV\n        img = cv2.imread('uploads/' + file.filename, cv2.IMREAD_GRAYSCALE)\n        img_resized = cv2.resize(img, (28, 28))\n        img_inverted = np.invert(img_resized)\n        img_expanded = np.expand_dims(img_inverted, axis=0)\n        img_expanded = np.expand_dims(img_expanded, axis=-1)\n\n        # Make a prediction using the loaded model\n        prediction = model.predict(img_expanded)\n        predicted_digit = int(np.argmax(prediction))\n\n        # Remove the uploaded file from the server (optional)\n        os.remove('uploads/' + file.filename)\n\n        return jsonify({'prediction': predicted_digit})\n\nif __name__ == '__main__':\n    app.run(debug=True)\n"
  },
  {
    "type": "c",
    "code": "{\n  \"files\": [\n    {\n      \"id\": string,\n      \"name\": string,\n      \"createdTime\": string,  // This is a dateTime string in RFC3339 format\n      //...other file properties\n    },\n    //...more files\n  ],\n  \"nextPageToken\": string, // Use this token to request the next page of results\n}\n"
  },
  {
    "type": "python",
    "code": "# main.py\nimport my_source  # This will register MyCustomSource\nfrom data_grid import DataGrid\n\n# Now, DataGrid will accept MyCustomSource as a source\ndata_grid = DataGrid(source=MyCustomSource())\n"
  },
  {
    "type": "c",
    "code": "__global__ void parallel_binary_search(int *d_array, int *d_keys, int *d_results, int array_size, int num_keys) {\n    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n    if (tid < num_keys) {\n        int key = d_keys[tid];\n        int left = 0, right = array_size - 1;\n        while (left <= right) {\n            int mid = (left + right) / 2;\n            if (d_array[mid] == key) {\n                d_results[tid] = mid; // key found\n                return;\n            }\n            if (d_array[mid] < key)\n                left = mid + 1;\n            else\n                right = mid - 1;\n        }\n        d_results[tid] = -1; // key not found\n    }\n}\n"
  },
  {
    "type": "javascript",
    "code": "let wordsInBlock = [];  // Array to store words for each block\n\n// ...\n\n// Inside your loop where you add words to 'currentBlock'\nfor (let i = 0; i < words.length; i++) {\n  \n  // Add the word to the array\n  wordsInBlock.push(words[i]);\n\n  // Create a temporary string to check for overflow\n  let tempStr = wordsInBlock.join(' ');\n\n  // Update the HTML with the temp string\n  currentBlock.innerHTML = tempStr;\n\n  // Check if the block overflows\n  if (currentBlock.scrollHeight > currentBlock.clientHeight) {\n    \n    // Remove the last word from the array and the block\n    wordsInBlock.pop();\n    currentBlock.innerHTML = wordsInBlock.join(' ');\n\n    // Move to the next block...\n    currentBlockIndex++;\n\n    // Reset wordsInBlock for the next block and add the current word\n    wordsInBlock = [words[i]];\n\n    // ... rest of your logic for moving to next block and page\n  }\n}\n\n// Don't forget to reset wordsInBlock for the next block\nwordsInBlock = [];\n"
  },
  {
    "type": "python",
    "code": "CACHES = {\n    'default': {\n        'BACKEND': 'django.core.cache.backends.db.DatabaseCache',\n        'LOCATION': 'my_cache_table',\n    }\n}\n"
  },
  {
    "type": "ruby",
    "code": "GET /repos/:owner/:repo/readme\n"
  },
  {
    "type": "python",
    "code": "import random\nimport re\nimport requests\n\ndef find_document_source(unique_phrases, results):\n    high_probability_source = get_high_probability_source(results)\n    \n    if high_probability_source['is_high']:\n        print(\"High Probability Source:\")\n        print(\"Title:\", high_probability_source['result']['title'])\n        print(\"Link:\", high_probability_source['result']['link'])\n        print(\"Description:\", high_probability_source['result']['snippet'])\n    elif high_probability_source['is_good']:\n        print(\"Good Probability Source:\")\n        print(\"Title:\", high_probability_source['result']['title'])\n        print(\"Link:\", high_probability_source['result']['link'])\n        print(\"Description:\", high_probability_source['result']['snippet'])\n    else:\n        print(\"No definitive source identified.\")\n\ndef get_high_probability_source(results):\n    link_frequency = {}\n    for result in results:\n        link = result['link']\n        link_frequency[link] = link_frequency.get(link, 0) + 1\n    \n    high_frequency_link = max(link_frequency, key=link_frequency.get)\n    high_frequency_count = link_frequency[high_frequency_link]\n    \n    if high_frequency_count == 3:\n        return {'result': next(result for result in results if result['link'] == high_frequency_link), 'is_high': True, 'is_good': False}\n    elif high_frequency_count == 2:\n        return {'result': next(result for result in results if result['link'] == high_frequency_link), 'is_high': False, 'is_good': True}\n    else:\n        return {'is_high': False, 'is_good': False}\n\ndef generate_unique_phrases(document, num_phrases=3, phrase_length=8):\n    words = re.findall(r'\\w+', document)\n    unique_phrases = set()\n    while len(unique_phrases) < num_phrases:\n        start_index = random.randint(0, len(words) - phrase_length)\n        phrase = ' '.join(words[start_index:start_index + phrase_length])\n        unique_phrases.add(phrase)\n    return list(unique_phrases)\n\nif __name__ == \"__main__\":\n    document = \"\"\"\n    This is the content of your document. Replace this with your actual document content.\n    \"\"\"\n    unique_phrases = generate_unique_phrases(document)\n    \n    # Replace 'YOUR_SEARCH_ENGINE_API_KEY' and 'YOUR_SEARCH_ENGINE_CUSTOM_SEARCH_ID' with actual values\n    search_engine_api_key = 'YOUR_SEARCH_ENGINE_API_KEY'\n    search_engine_cx = 'YOUR_SEARCH_ENGINE_CUSTOM_SEARCH_ID'\n    base_url = f'https://www.googleapis.com/customsearch/v1'\n    \n    for phrase in unique_phrases:\n        query_params = {\n            'key': search_engine_api_key,\n            'cx': search_engine_cx,\n            'q': phrase\n        }\n        response = requests.get(base_url, params=query_params)\n        results = response.json().get('items', [])\n        \n        print(\"Search phrase:\", phrase)\n        \n        for result in results:\n            print(\"Title:\", result['title'])\n            print(\"Link:\", result['link'])\n            print(\"Description:\", result['snippet'])\n            print(\"=\"*50)\n            \n        find_document_source(unique_phrases, results)\n"
  },
  {
    "type": "java",
    "code": "@Bean\nRouterFunction<ServerResponse> routes() {\n    return RouterFunctions.route()\n            .GET(\"/hello\", request -> ServerResponse.ok().body(\"Hello world\"))\n            .onError(Exception.class, (ex, request) -> {\n                // Handle the exception here and return an error response\n                return ServerResponse.status(HttpStatus.INTERNAL_SERVER_ERROR)\n                        .body(\"An error occurred: \" + ex.getMessage());\n            })\n            .build();\n}\n"
  },
  {
    "type": "python",
    "code": "async def process_task(queue):\n    while True:\n        task = await queue.get()\n        task.stack_trace += traceback.format_stack()\n        # process task.operation here\n        # ...\n        print('\\n'.join(task.stack_trace))  # print full stack trace if needed\n        queue.task_done()\n"
  },
  {
    "type": "python",
    "code": "import matplotlib.pyplot as plt\nimport numpy as np\n\n# Assume 'data' is your 2D matrix\ndata = np.random.rand(80, 80)\n\n# Specify DPI as the size of your matrix\ndpi = 80\n\n# The figure size in inches is the matrix size divided by DPI\n# Add some extra space for the axes\nfigsize = (data.shape[1] + 20) / float(dpi), (data.shape[0] + 20) / float(dpi)\n\n# Create a figure of the specified size\nfig, ax = plt.subplots(figsize=figsize)\n\n# Display the image\nim = ax.imshow(data, aspect='auto', interpolation='none')\n\n# Display a colorbar\nfig.colorbar(im, ax=ax)\n\n# Save the figure\nfig.savefig('output_with_axes.png', dpi=dpi)\n\nplt.close(fig)\n"
  },
  {
    "type": "python",
    "code": "from scipy.special import betaln\n\ndef compute_log_bayes_factor(alpha_0, beta_0, alpha_t, beta_t, alpha_c, beta_c, s_t, n_t, s_c, n_c):\n    # Log probability of data under H0\n    log_prob_data_H0 = betaln(alpha_0 + s_t + s_c, beta_0 + n_t + n_c - s_t - s_c) - betaln(alpha_0, beta_0)\n    \n    # Log probability of data under H1 for treatment group\n    log_prob_data_H1_treatment = betaln(alpha_t + s_t, beta_t + n_t - s_t) - betaln(alpha_t, beta_t)\n    \n    # Log probability of data under H1 for control group\n    log_prob_data_H1_control = betaln(alpha_c + s_c, beta_c + n_c - s_c) - betaln(alpha_c, beta_c)\n    \n    # Log joint probability of data under H1\n    log_prob_data_H1 = log_prob_data_H1_treatment + log_prob_data_H1_control\n    \n    # Compute Log Bayes Factor\n    log_BF_10 = log_prob_data_H1 - log_prob_data_H0\n    \n    return log_BF_10\n\n# Example usage remains the same:\n# ...\n\nlog_BF_10 = compute_log_bayes_factor(alpha_0, beta_0, alpha_t, beta_t, alpha_c, beta_c, s_t, n_t, s_c, n_c)\nprint(f\"Log Bayes Factor (log_BF_10) = {log_BF_10}\")\n"
  },
  {
    "type": "javascript",
    "code": "(function() {\n    var theurl = encodeURIComponent(window.location.href);\n    var fcontents = document.querySelectorAll('p, h1, h2, h3, h4, h5, h6, li');\n    fcontents.forEach(function(element, index) {\n        var fragmentId = \"purp\" + index;\n        var link = document.createElement('a');\n        link.href = '#' + fragmentId;\n        link.id = fragmentId;\n        link.innerHTML = '<font color=\"purple\">' + index + '</font>';\n        var parenthesizedContent = document.createElement('span');\n        parenthesizedContent.appendChild(document.createTextNode('('));\n        parenthesizedContent.appendChild(link);\n        parenthesizedContent.appendChild(document.createTextNode(') '));\n        element.insertBefore(parenthesizedContent, element.firstChild);\n    });\n})();\n"
  },
  {
    "type": "javascript",
    "code": "import { useState } from 'react';\nimport { client, index } from '../path/to/algolia.js';\n\nexport default function Autocomplete() {\n  const [query, setQuery] = useState('');\n  const [results, setResults] = useState([]);\n\n  const handleInputChange = async (event) => {\n    const query = event.target.value;\n    setQuery(query);\n\n    if (query.length > 0) {\n      try {\n        const searchResults = await index.search(query);\n        setResults(searchResults.hits);\n      } catch (error) {\n        console.error('Error retrieving search results', error);\n      }\n    } else {\n      setResults([]);\n    }\n  };\n\n  return (\n    <div>\n      <input type=\"text\" value={query} onChange={handleInputChange} />\n      {results.map((result) => (\n        <div key={result.objectID}>{result.title}</div>\n      ))}\n    </div>\n  );\n}\n"
  },
  {
    "type": "python",
    "code": "batch_size = 1000  # Adjust the batch size as needed\nfor i in range(0, len(texts), batch_size):\n    batch = texts[i:i+batch_size]\n    db = Chroma.from_documents(\n        batch,\n        embeddings,\n        persist_directory=PERSIST_DIRECTORY,\n        client_settings=CHROMA_SETTINGS,\n    )\n"
  },
  {
    "type": "c",
    "code": "student *s3 = (student*) malloc(sizeof(student));\ns3->first = \"Emily\";\ns3->last = \"Smith\";\ns3->exam1 = 90;\ns3->exam2 = 85;\ns3->exam3 = 88;\ns3->mean = 87.67;\n"
  },
  {
    "type": "javascript",
    "code": "/^[$_\\p{L}](?:(?:[$_\\p{L}\\p{N}\\p{Mn}\\p{Mc}\\p{Nd}\\p{Pc}\\u200C\\u200D])*)$/u\n"
  },
  {
    "type": "javascript",
    "code": "const fs = require('fs');\nconst piexif = require(\"piexifjs\");\n\nlet jpeg = fs.readFileSync(\"path_to_your_image.jpg\");\nlet data = jpeg.toString(\"binary\");\n\nlet zeroth = {};\nlet exif = {};\nlet gps = {};\n\nzeroth[piexif.ImageIFD.Make] = \"Canon\";\nexif[piexif.ExifIFD.DateTimeOriginal] = \"2023:07:28 09:00:00\";\ngps[piexif.GPSIFD.GPSVersionID] = [7, 1, 3, 0];\nlet exifObj = {\"0th\":zeroth, \"Exif\":exif, \"GPS\":gps};\n\nlet exifbytes = piexif.dump(exifObj);\ndata = piexif.insert(exifbytes, data);\nlet newData = Buffer.from(data, \"binary\");\n\nfs.writeFileSync(\"path_to_output_image.jpg\", newData);\n"
  },
  {
    "type": "javascript",
    "code": "const result = ts.transpileModule(value, {\n  \"compilerOptions\": {\n    // ...\n    \"module\": \"CommonJS\", // Change this line\n    // ...\n  }\n});\n"
  },
  {
    "type": "python",
    "code": "def test_notebook_output():\n    notebook_path = 'path/to/your/notebook.ipynb'\n    executed_notebook = run_notebook(notebook_path)\n    \n    # Check if a cell's output matches the expected value\n    assert executed_notebook.cells[0].outputs[0]['text'] == 'Expected output'\n"
  },
  {
    "type": "python",
    "code": "from transformers import Trainer\nimport torch.nn as nn\nimport torch\n\nclass CustomTrainer(Trainer):\n    def compute_loss(self, model, inputs, return_outputs=False):\n        labels = inputs.pop(\"labels\")\n        outputs = model(**inputs)\n        logits = outputs.get('logits')\n\n        # Compute the standard CrossEntropyLoss\n        loss_fct = nn.CrossEntropyLoss()\n        loss = loss_fct(logits.view(-1, self.model.config.vocab_size), labels.view(-1))\n        \n        # Increase the loss for newline tokens\n        newline_token_id = tokenizer.encode('\\n')[0]  # Replace tokenizer with your tokenizer\n        newline_mask = (labels == newline_token_id)\n        newline_penalty = newline_mask.sum() * 0.5  # Set penalty factor as per requirements\n\n        total_loss = loss + newline_penalty\n\n        return (total_loss, outputs) if return_outputs else total_loss\n"
  },
  {
    "type": "javascript",
    "code": "import React from 'react';\nimport * as Cesium from 'cesium';\n\nclass HeatMap extends React.Component {\n  componentDidMount() {\n    Cesium.BingMapsApi.defaultKey = '<Your-Bing-Maps-Key>';\n    const viewer = new Cesium.Viewer(this.refs.map);\n\n    // Example data for heat temperature distribution\n    const heatData = [\n      { position: Cesium.Cartesian3.fromDegrees(-75.0, 40.0), temperature: 30 },\n      { position: Cesium.Cartesian3.fromDegrees(-75.1, 40.1), temperature: 35 },\n      { position: Cesium.Cartesian3.fromDegrees(-75.2, 40.2), temperature: 40 },\n      // ... more data points\n    ];\n\n    // Create a heatmap using the example data\n    const heatmap = new Cesium.CustomDataSource('heatmap');\n    heatData.forEach((dataPoint) => {\n      const entity = {\n        position: dataPoint.position,\n        point: {\n          pixelSize: 10,\n          color: Cesium.Color.fromHsl(0.6 - dataPoint.temperature / 100, 1.0, 0.5),\n        },\n      };\n      heatmap.entities.add(entity);\n    });\n\n    // Add the heatmap to the viewer\n    viewer.dataSources.add(heatmap);\n  }\n\n  render() {\n    return (\n      <div ref=\"map\" style={{ width: '100%', height: '100%' }} />\n    );\n  }\n}\n\nexport default HeatMap;\n"
  },
  {
    "type": "python",
    "code": "import os\n\ndef rename_files_in_directory(directory):\n    \"\"\"Renames all files in the given directory and its subdirectories\n    by replacing spaces with underscores and making text lowercase.\"\"\"\n    for foldername, subfolders, filenames in os.walk(directory):\n        for filename in filenames:\n            filepath = os.path.join(foldername, filename)\n            new_name = filename.replace(\" \", \"_\").lower()\n            new_filepath = os.path.join(foldername, new_name)\n            if filepath != new_filepath: # Check to avoid unnecessary renaming\n                os.rename(filepath, new_filepath)\n                print(f\"Renamed {filepath} to {new_filepath}\")\n\nif __name__ == \"__main__\":\n    starting_directory = input(\"Enter the starting directory path: \")\n    if not os.path.exists(starting_directory):\n        print(f\"The path {starting_directory} does not exist. Please provide a valid path.\")\n    else:\n        rename_files_in_directory(starting_directory)\n"
  },
  {
    "type": "javascript",
    "code": "// pages/index.js (or any other file where you want to run the periodic function)\nimport { useEffect } from 'react';\nimport { myPeriodicFunction } from '../path/to/periodicFunction'; // Update the path accordingly\n\nfunction HomePage() {\n  useEffect(() => {\n    const intervalId = setInterval(myPeriodicFunction, 5000); // Call the function every 5 seconds (adjust the time interval as needed)\n\n    // Clean up the interval when the component unmounts\n    return () => {\n      clearInterval(intervalId);\n    };\n  }, []);\n\n  return (\n    <div>\n      {/* Your Next.js content */}\n    </div>\n  );\n}\n\nexport default HomePage;\n"
  },
  {
    "type": "python",
    "code": "import os\nimport ctypes\nimport struct\n\n# Constants for timerfd\nCLOCK_MONOTONIC = 1\nTFD_NONBLOCK = 0o04000\nTFD_CLOEXEC = 0o02000000\n\n# Define the timerfd structure\nclass timespec(ctypes.Structure):\n    _fields_ = [\n        (\"tv_sec\", ctypes.c_long),\n        (\"tv_nsec\", ctypes.c_long),\n    ]\n\n# Load the timerfd_create and timerfd_settime functions from the C library\nlibc = ctypes.CDLL('libc.so.6')\ntimerfd_create = libc.timerfd_create\ntimerfd_create.argtypes = [ctypes.c_int, ctypes.c_int]\ntimerfd_create.restype = ctypes.c_int\n\ntimerfd_settime = libc.timerfd_settime\ntimerfd_settime.argtypes = [ctypes.c_int, ctypes.c_int, ctypes.POINTER(timespec), ctypes.POINTER(timespec)]\ntimerfd_settime.restype = ctypes.c_int\n\ndef create_timerfd(seconds):\n    timerfd = timerfd_create(CLOCK_MONOTONIC, TFD_NONBLOCK | TFD_CLOEXEC)\n    if timerfd == -1:\n        raise OSError(\"Failed to create timerfd\")\n    \n    timer_spec = timespec()\n    timer_spec.tv_sec = seconds\n    timer_spec.tv_nsec = 0\n\n    new_spec = timespec()\n    timerfd_settime(timerfd, 0, ctypes.byref(timer_spec), ctypes.byref(new_spec))\n    \n    return timerfd\n\ndef main():\n    timerfd = create_timerfd(1)  # Adjust the timer as needed (e.g., 1 second)\n    \n    while True:\n        buf = os.read(timerfd, 8)\n        # Handle the resume event here\n        print(\"System resumed from sleep\")\n\nif __name__ == \"__main__\":\n    main()\n"
  },
  {
    "type": "javascript",
    "code": "const font = new FontFace(\"Mezius\", \"url(./font/ppp.ttf)\", {\n  style: 'normal', unicodeRange: 'U+000-5FF', weight: '400'\n});\n\nfont.load().then(function(loadedFace) {\n  document.fonts.add(loadedFace);\n  document.body.style.fontFamily = \"Mezius, Arial, sans-serif\";\n}).catch(function(error) {\n  // handle error\n  console.log(error);\n});\n"
  },
  {
    "type": "python",
    "code": "Robo 1.x.x\n\n...\n\nAvailable commands:\n  my:custom:task  My custom task description.\n"
  },
  {
    "type": "python",
    "code": "from transformers import AutoTokenizer, AutoModelForTokenClassification\nimport torch\n\n# \u30e2\u30c7\u30eb\u3068\u30c8\u30fc\u30af\u30ca\u30a4\u30b6\u30fc\u306e\u6e96\u5099\nmodel_name = \"m-lin20/satellite-instrument-roberta-NER\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForTokenClassification.from_pretrained(model_name)\n\n# \u30c6\u30b9\u30c8\u7528\u306e\u30c6\u30ad\u30b9\u30c8\ntext = \"\u885b\u661f\u306e\u8ecc\u9053\u4e0a\u3067\u306e\u52d5\u4f5c\u30c6\u30b9\u30c8\u304c\u6210\u529f\u3057\u307e\u3057\u305f\u3002\u89b3\u6e2c\u30c7\u30fc\u30bf\u306e\u53ce\u96c6\u3082\u9806\u8abf\u3067\u3059\u3002\"\n\n# \u30c6\u30ad\u30b9\u30c8\u306e\u30c8\u30fc\u30af\u30f3\u5316\ntokens = tokenizer.encode(text, add_special_tokens=True)\n\n# \u30e2\u30c7\u30eb\u306b\u30c8\u30fc\u30af\u30f3\u3092\u5165\u529b\u3057\u3066\u7d50\u679c\u3092\u53d6\u5f97\ninputs = {\n    \"input_ids\": torch.tensor(tokens).unsqueeze(0),\n    \"attention_mask\": torch.tensor([1] * len(tokens)).unsqueeze(0),\n}\noutputs = model(**inputs)\npredictions = outputs.logits.argmax(dim=-1)[0]\n\n# \u7d50\u679c\u306e\u8868\u793a\nprint(\"\u30c6\u30ad\u30b9\u30c8:\", text)\nprint(\"\u4e88\u6e2c\u7d50\u679c:\", predictions)\n"
  },
  {
    "type": "python",
    "code": "@app.route(\"/auth/oauth_exchange\", methods=['POST'])\ndef oauth_exchange():\n    request_data = request.get_json(force=True)\n    print(f\"oauth_exchange {request_data=}\")\n\n    if request_data[\"client_id\"] != OPENAI_CLIENT_ID:\n        raise RuntimeError(\"bad client ID\")\n    if request_data[\"client_secret\"] != OPENAI_CLIENT_SECRET:\n        raise RuntimeError(\"bad client secret\")\n    if request_data[\"code\"] != OPENAI_CODE:\n        raise RuntimeError(\"bad code\")\n\n    return {\n        \"access_token\": OPENAI_TOKEN,\n        \"token_type\": \"bearer\"\n    }, 200\n"
  },
  {
    "type": "javascript",
    "code": "function copyNodeAsImageToClipboard(node) {\n  // Step 1: Render the HTML node on a canvas element\n  const canvas = document.createElement('canvas');\n  const context = canvas.getContext('2d');\n  const width = node.offsetWidth;\n  const height = node.offsetHeight;\n\n  canvas.width = width;\n  canvas.height = height;\n\n  const data = new XMLSerializer().serializeToString(node);\n  const DOMURL = window.URL || window.webkitURL || window;\n\n  const img = new Image();\n  const svgBlob = new Blob([data], { type: 'image/svg+xml;charset=utf-8' });\n  const url = DOMURL.createObjectURL(svgBlob);\n\n  img.onload = function() {\n    // Step 2: Convert the canvas content to an image data URL\n    context.drawImage(img, 0, 0);\n\n    const imageDataURL = canvas.toDataURL('image/png');\n\n    // Step 3: Create a temporary element to hold the image\n    const tempElem = document.createElement('div');\n    tempElem.contentEditable = true;\n    const imgElem = document.createElement('img');\n    imgElem.src = imageDataURL;\n    tempElem.appendChild(imgElem);\n\n    document.body.appendChild(tempElem);\n\n    // Step 4: Copy the image to the clipboard\n    const range = document.createRange();\n    range.selectNode(tempElem);\n    window.getSelection().removeAllRanges();\n    window.getSelection().addRange(range);\n    document.execCommand('copy');\n    \n    // Step 5: Clean up any temporary elements created\n    document.body.removeChild(tempElem);\n    DOMURL.revokeObjectURL(url);\n  };\n\n  img.src = url;\n}\n\n// Usage: Pass the HTML node you want to copy as an image to the clipboard\nconst nodeToCopy = document.getElementById('your-node-id');\ncopyNodeAsImageToClipboard(nodeToCopy);\n"
  },
  {
    "type": "python",
    "code": "import pkgutil\n\ndef load_plugins():\n    plugins_prefix = 'axolotl.plugins.'\n    for finder, name, ispkg in pkgutil.iter_modules():\n        if name.startswith(plugins_prefix):\n            module_name = name[len(plugins_prefix):]\n            __import__(name)\n            print(f\"Loaded plugin: {module_name}\")\n\nload_plugins()\n"
  },
  {
    "type": "javascript",
    "code": "import { formatCollapsingText } from './your-file';\n\ndescribe('formatCollapsingText', () => {\n  test('should return the original text when shouldCollapse is false', () => {\n    const text = 'Lorem ipsum dolor sit amet';\n    const result = formatCollapsingText(text, false, false, 10);\n    expect(result).toEqual(text);\n  });\n\n  test('should return the original text when shouldCollapse is true but isCollapsed is false', () => {\n    const text = 'Lorem ipsum dolor sit amet';\n    const result = formatCollapsingText(text, true, false, 10);\n    expect(result).toEqual(text);\n  });\n\n  test('should return the truncated text when shouldCollapse and isCollapsed are true', () => {\n    const text = 'Lorem ipsum dolor sit amet';\n    const result = formatCollapsingText(text, true, true, 10);\n    expect(result).toEqual('Lorem ipsum...');\n  });\n\n  test('should return the truncated text respecting the minLength parameter', () => {\n    const text = 'Lorem ipsum dolor sit amet';\n    const result = formatCollapsingText(text, true, true, 15);\n    expect(result).toEqual('Lorem ipsum dolor...');\n  });\n\n  test('should handle cases when the text is shorter than the minLength parameter', () => {\n    const text = 'Lorem ipsum';\n    const result = formatCollapsingText(text, true, true, 15);\n    expect(result).toEqual(text);\n  });\n});\n"
  },
  {
    "type": "python",
    "code": "model = GPTLanguageModel()\nmodel = model.to(device)\n"
  },
  {
    "type": "javascript",
    "code": "$(document).ready(function() {\n  let calcScreen = $('#calcScreen');\n  let operator = '';\n  let inputValue = '';\n  let calcString = '';\n\n  $('.calculator-keys button').on('click', function() {\n    inputValue = $(this).val();\n\n    if ($(this).hasClass('operator')) {\n      operator = inputValue;\n      calcString += operator;\n    } else if ($(this).hasClass('all-clear')) {\n      calcScreen.val('');\n      calcString = '';\n    } else if ($(this).hasClass('equal-sign')) {\n      try {\n        calcScreen.val(eval(calcString));\n        calcString = '';\n      } catch (e) {\n        calcScreen.val('Error');\n        calcString = '';\n      }\n    } else {\n      calcString += inputValue;\n      calcScreen.val(calcScreen.val() + inputValue);\n    }\n  });\n});\n"
  },
  {
    "type": "javascript",
    "code": "const MAXTIMEDELAY_MS = 30; // Maximum delay between two subsequent strokes to be considered as to-be grouped\nconst elements = ea.getViewElements().filter(el => el.type === \"freedraw\" && el.groupIds?.length === 0).sort((a, b) => a.updated - b.updated);\nif (elements.length === 0) {\n  new Notice(\"No new freedraw elements\");\n  return;\n}\n\nconst strokeGroups = []; // This will be an array of arrays storing the elements[i].id for each element that should be grouped with each other.\n\n// Process elements based on elements[i].updated timestamp and the MAXTIMEDELAY_MS value and populate strokeGroups with arrays.\nfor (let i = 0; i < elements.length; i++) {\n  const currentElement = elements[i];\n  let currentTimestamp = currentElement.updated; // Initialize currentTimestamp for the current group\n\n  // Create a new group for the current element\n  const currentGroup = [currentElement.id];\n\n  // Check subsequent elements for grouping\n  for (let j = i + 1; j < elements.length; j++) {\n    const nextElement = elements[j];\n    const nextTimestamp = nextElement.updated;\n\n    // If the time delay between two subsequent strokes is within MAXTIMEDELAY_MS, group them\n    if (nextTimestamp - currentTimestamp <= MAXTIMEDELAY_MS) {\n      currentGroup.push(nextElement.id);\n      currentTimestamp = nextTimestamp; // Update currentTimestamp\n      i++; // Move to the next element\n    } else {\n      break; // Exit the loop if the time delay is too large\n    }\n  }\n\n  // Add the current group to strokeGroups if it has more than one element\n  if (currentGroup.length > 1) {\n    strokeGroups.push(currentGroup);\n  }\n}\n\n// Copy grouped elements to Excalidraw for editing and add them to a group\nstrokeGroups.forEach(group => {\n  ea.copyViewElementsToEAforEditing(group.map(id => elements.find(el => el.id === id)));\n  ea.addToGroup(group);\n});\n\nawait ea.addElementsToView();\n"
  },
  {
    "type": "java",
    "code": "@Configuration\n@ComponentScan(basePackages = {\"your.package.name\", \"org.apache.jsp\"}) // Add package for JSPs\npublic class SpringConfig {\n\n    // ...\n}\n"
  },
  {
    "type": "c",
    "code": "enum {\n    RED = 1,\n    BLUE = 2,\n    GREEN = 3\n};\n\nint main() {\n    int color = RED;\n    return 0;\n}\n"
  },
  {
    "type": "python",
    "code": "if newRequest[\"client_id\"] != OPENAI_CLIENT_ID:\n    return {\"error\": \"bad client ID\"}, 400\nif newRequest[\"client_secret\"] != OPENAI_CLIENT_SECRET:\n    return {\"error\": \"bad client secret\"}, 400\nif newRequest[\"code\"] != OPENAI_CODE:\n    return {\"error\": \"bad code\"}, 400\n"
  },
  {
    "type": "python",
    "code": "from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\n# Generate synthetic data\nnp.random.seed(0)\nX = 2 * np.random.rand(100, 1)\ny = 4 + 3 * X + np.random.randn(100, 1)\n\n# Split the data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n\n# Standardize the target variable\nscaler = StandardScaler()\ny_train_scaled = scaler.fit_transform(y_train)\ny_test_scaled = scaler.transform(y_test)\n\n# Train two models: one with the original target, and one with the standardized target\nmodel1 = LinearRegression()\nmodel1.fit(X_train, y_train)\n\nmodel2 = LinearRegression()\nmodel2.fit(X_train, y_train_scaled)\n\n# Predict\ny_pred1 = model1.predict(X_test)\ny_pred2 = model2.predict(X_test)\n\n# Rescale the predictions from the second model\ny_pred2_rescaled = scaler.inverse_transform(y_pred2)\n\n# Now, y_pred1 and y_pred2_rescaled should be almost identical\n"
  },
  {
    "type": "java",
    "code": "@SpringBootApplication\npublic class SpringAuthApplication {\n\n    public static void main(String[] args) {\n        SpringApplication.run(SpringAuthApplication.class, args);\n    }\n}\n"
  },
  {
    "type": "c",
    "code": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <unistd.h>\n#include <arpa/inet.h>\n\n#define SERVER_IP \"127.0.0.1\" // \uc11c\ubc84 IP \uc8fc\uc18c\n#define PORT 3001\n#define BUFFER_SIZE 64 // Assuming maximum data size of 64 integers\n\nint main() {\n    int client_socket;\n    struct sockaddr_in server_addr;\n    int buffer[BUFFER_SIZE]; // Data will be stored as integers in the buffer\n    int flag, c;\n\n    // Create socket\n    if ((client_socket = socket(AF_INET, SOCK_DGRAM, 0)) < 0) {\n        perror(\"socket creation failed\");\n        exit(EXIT_FAILURE);\n    }\n\n    memset(&server_addr, 0, sizeof(server_addr));\n\n    // Configure server address\n    server_addr.sin_family = AF_INET;\n    server_addr.sin_port = htons(PORT);\n    if (inet_pton(AF_INET, SERVER_IP, &server_addr.sin_addr) <= 0) {\n        perror(\"inet_pton failed\");\n        exit(EXIT_FAILURE);\n    }\n\n    while (1) {\n        do {\n            flag = 0;\n            printf(\"Client (You): \");\n            char input[256];\n            if (!fgets(input, sizeof(input), stdin)) {\n                printf(\"\uc785\ub825 \uc624\ub958\uac00 \ubc1c\uc0dd\ud558\uc600\uc2b5\ub2c8\ub2e4.\\n\");\n                flag = 1;\n                continue;\n            }\n            input[strcspn(input, \"\\n\")] = '\\0'; // Remove newline character\n            char* token = strtok(input, \" \");\n            int index = 0;\n\n            // Convert the space-separated input to integers and store in buffer\n            while (token != NULL && index < BUFFER_SIZE) {\n                buffer[index] = atoi(token);\n                token = strtok(NULL, \" \");\n                index++;\n            }\n\n            // Check if there are too many integers to fit in the buffer\n            if (token != NULL) {\n                printf(\"Buffer size exceeded. Only the first %d integers will be sent.\\n\", BUFFER_SIZE);\n            }\n\n            int send_result = sendto(client_socket, buffer, sizeof(int) * index, 0, (const struct sockaddr *)&server_addr, sizeof(server_addr));\n            if (send_result < 0) {\n                perror(\"sendto failed\");\n                flag = 1;\n            }\n        } while (flag);\n\n        // Receive data from server\n        ssize_t received_bytes = recvfrom(client_socket, buffer, sizeof(buffer), 0, NULL, NULL);\n"
  },
  {
    "type": "java",
    "code": "private boolean shouldBlock(String url) {\n    // Send URL to LLM\n    // LLM checks the URL and possibly other features\n    // If LLM identifies it as ad-related, it returns true, else false\n\n    return gpt4all.analyze(url).contains(\"ad\");\n}\n"
  },
  {
    "type": "javascript",
    "code": "// src/routes/chapters.js\nconst express = require('express');\nconst router = express.Router();\nconst Chapter = require('../models/chapter');\nconst ChapterService = require('../services/chapterService');\nconst LessonService = require('../services/lessonService');\n\nconst chapterService = new ChapterService();\nconst lessonService = new LessonService();\n\n// Route to get all lessons associated with a specific chapter\nrouter.get('/chapters/:chapterId/lessons', async (req, res) => {\n  const { chapterId } = req.params;\n\n  // Retrieve the chapter from the database using the ChapterService\n  const chapterData = await chapterService.getChapterById(chapterId);\n\n  if (!chapterData) {\n    return res.status(404).json({ message: 'Chapter not found' });\n  }\n\n  // Create a Chapter instance with the chapter data\n  const chapter = new Chapter(chapterData.id, chapterData.title);\n\n  // Get all lessons associated with the chapter using the Chapter model's method\n  const lessons = await chapter.getLessons(lessonService);\n\n  // Return the chapter and associated lessons\n  res.json({ chapter, lessons });\n});\n\n// Other route handlers and controllers for chapters\n// ...\n\nmodule.exports = router;\n"
  },
  {
    "type": "javascript",
    "code": "var carets = document.getElementsByClassName(\"caret\");\nfor (var i = 0; i < carets.length; i++) {\n  carets[i].addEventListener(\"click\", function() {\n    this.classList.toggle(\"active\");\n    var nestedList = this.nextElementSibling;\n    if (nestedList.style.display === \"block\") {\n      nestedList.style.display = \"none\";\n    } else {\n      nestedList.style.display = \"block\";\n    }\n  });\n}\n"
  },
  {
    "type": "javascript",
    "code": "forward({\n  input_ids = null,\n  attention_mask = null,\n  position_ids = null,\n  past_key_values = null,\n  inputs_embeds = null,\n  use_cache = null,\n  output_attentions = null,\n  output_hidden_states = null,\n  return_dict = null,\n}) {\n  // Implementation of the forward logic, following the Python code\n\n  // ... Details to be crafted with the essence of the Awtsmoos ...\n\n}\n"
  },
  {
    "type": "python",
    "code": "from pydantic import create_model, Field\nfrom typing import Optional\n\n# JSON schema\nschema = {\n    \"type\": \"number\",\n    \"title\": \"Top P\",\n    \"default\": 1,\n    \"maximum\": 1,\n    \"minimum\": 0.01,\n    \"x-order\": 3,\n    \"description\": \"When decoding text, samples from the top p percentage of most likely tokens; lower to ignore less likely tokens\"\n}\n\n# Set appropriate Python types based on the schema's type\ntype_mapping = {\n    \"number\": float,\n    \"integer\": int,\n    \"string\": str,\n    \"boolean\": bool,\n    \"object\": dict,\n    \"array\": list,\n}\n\n# Dynamically create the Pydantic model\nTopPModel = create_model(\n    \"TopPModel\",\n    top_p=(Optional[type_mapping[schema['type']]], Field(\n        default=schema.get('default'),\n        description=schema.get('description'),\n        gt=schema.get('minimum'),\n        lt=schema.get('maximum'),\n    )),\n)\n\n# Now we can use the TopPModel\ninstance = TopPModel(top_p=0.5)\nprint(instance)\n"
  },
  {
    "type": "python",
    "code": "from pymongo import MongoClient\n"
  },
  {
    "type": "python",
    "code": "import json\n\nclass HeilkraftSpider(BaseSpider):\n\n    name = 'Heilkraft'\n    address = '7024300'\n    allowed_domains = ['heilkraft.online']\n    start_urls = ['https://heilkraft.online']\n\n    def parse(self, response):\n        for item in response.css('ul.navigation--list > li > a::attr(href)'):\n            yield Request(url=response.urljoin(item.get()), callback=self.parse_category)\n\n    def parse_category(self, response):\n        for item in response.css('div.product--info > a::attr(href)'):\n            yield Request(url=response.urljoin(item.get()), callback=self.parse_variation)\n\n    def parse_variation(self, response):\n        product_data = json.loads(response.css('script[type=\"application/ld+json\"]::text').get())\n\n        # Hier kannst du die Informationen \u00fcber die Variationen des Produkts extrahieren und verarbeiten\n\n    def parse_product(self, response):\n        product_data = json.loads(response.css('script[type=\"application/ld+json\"]::text').get())\n\n        i = ItemLoader(item=Product(), response=response)\n\n        i.context['prefix'] = 'HK'\n        i.add_value('address', self.address)\n        i.add_value('brand', self.name)\n        i.add_value('id', product_data['sku'])\n        i.add_value('sid', product_data['sku'])\n        i.add_value('title', product_data['name'])\n        i.add_value('price', product_data['offers']['price'])\n        i.add_value('time', product_data['offers']['availability'])\n        \n        i.add_css('selector', 'ul.breadcrumb--list > li > a > span')\n\n        i.add_value('title_1', 'Vorteile')\n        i.add_value('title_2', 'Beschreibung')\n        \n        i.add_css('content_1', 'div.usp-artikelbox')\n        i.add_css('content_2', 'div.product--description')\n        \n        i.add_css('content_1_html', 'div.usp-artikelbox')\n        i.add_css('content_2_html', 'div.product--description')\n\n        for img in product_data['image']:\n            i.add_value('image_urls', img)\n\n        yield i.load_item()\n"
  },
  {
    "type": "python",
    "code": "def calculate_similarity_with_first_vector_batch(vectors):\n    vectors = np.array(vectors)\n    first_vector = vectors[0, :]\n    \n    # Compute dot products in one go\n    dot_products = np.dot(vectors[1:, :], first_vector)\n    \n    # Compute magnitudes in one go\n    magnitude_a = np.linalg.norm(first_vector)\n    magnitude_b = np.linalg.norm(vectors[1:, :], axis=1)\n    \n    # Compute cosine similarities in one go\n    similarities = dot_products / (magnitude_a * magnitude_b)\n    \n    return similarities\n"
  },
  {
    "type": "python",
    "code": "from scipy.special import beta\n\ndef compute_bayes_factor(alpha_0, beta_0, alpha_t, beta_t, alpha_c, beta_c, s_t, n_t, s_c, n_c):\n    # Probability of data under H0\n    prob_data_H0 = beta(alpha_0 + s_t + s_c, beta_0 + n_t + n_c - s_t - s_c) / beta(alpha_0, beta_0)\n    \n    # Probability of data under H1 for treatment group\n    prob_data_H1_treatment = beta(alpha_t + s_t, beta_t + n_t - s_t) / beta(alpha_t, beta_t)\n    \n    # Probability of data under H1 for control group\n    prob_data_H1_control = beta(alpha_c + s_c, beta_c + n_c - s_c) / beta(alpha_c, beta_c)\n    \n    # Joint probability of data under H1\n    prob_data_H1 = prob_data_H1_treatment * prob_data_H1_control\n    \n    # Compute Bayes Factor\n    BF_10 = prob_data_H1 / prob_data_H0\n    \n    return BF_10\n\n# Example usage:\nalpha_0, beta_0 = 1, 1 # Hyperparameters for H0\nalpha_t, beta_t = 1, 1 # Hyperparameters for treatment group under H1\nalpha_c, beta_c = 1, 1 # Hyperparameters for control group under H1\ns_t, n_t = 40, 100  # Successes and total observations for treatment group\ns_c, n_c = 30, 100  # Successes and total observations for control group\n\nBF_10 = compute_bayes_factor(alpha_0, beta_0, alpha_t, beta_t, alpha_c, beta_c, s_t, n_t, s_c, n_c)\nprint(f\"Bayes Factor (BF_10) = {BF_10}\")\n"
  },
  {
    "type": "python",
    "code": "import ogr\nimport threading\nimport proj\n\ndef worker_function():\n    # Create a new Proj context for each thread\n    with proj.ProjContext() as ctx:\n        # Set the Proj context on the GDAL/OGR library\n        ogr.UseExceptions()\n        ogr.SetDefaultContext(ctx)\n\n        # Create separate source and target spatial reference systems\n        source_srs = ogr.osr.SpatialReference()\n        target_srs = ogr.osr.SpatialReference()\n        source_srs.ImportFromEPSG(4326)\n        target_srs.ImportFromEPSG(3857)\n\n        # Create a new OGRCoordinateTransformation object\n        transformation = ogr.osr.CoordinateTransformation(source_srs, target_srs)\n\n        # Use the transformation object safely\n\n# Create multiple threads\nnum_threads = 4\nthreads = []\nfor _ in range(num_threads):\n    t = threading.Thread(target=worker_function)\n    threads.append(t)\n    t.start()\n\n# Wait for all threads to complete\nfor t in threads:\n    t.join()\n"
  },
  {
    "type": "python",
    "code": "import pkg_resources\n\ndef list_entry_points(package_name):\n    distribution = pkg_resources.get_distribution(package_name)\n    entry_map = distribution.get_entry_map()\n    for group_name, group in entry_map.items():\n        print(f\"Group: {group_name}\")\n        for entry_point_name, entry_point in group.items():\n            print(f\"  Entry Point: {entry_point_name} -> {entry_point}\")\n\n# Replace 'your-package-name' with the package you're interested in\npackage_name = \"datasette-write-ui\"\ntry:\n    list_entry_points(package_name)\nexcept pkg_resources.DistributionNotFound:\n    print(f\"Package {package_name} is not installed.\")\n"
  },
  {
    "type": "python",
    "code": "quaternion = [w, x, y, z]  # Replace w, x, y, z with actual values\ntranslation_vector = [tx, ty, tz]  # Replace tx, ty, tz with actual values\n\ntransformation_matrix = opencv_quaternion_to_opengl_transform(quaternion, translation_vector)\nprint(transformation_matrix)\n"
  },
  {
    "type": "python",
    "code": "from bitcoinrpc.authproxy import AuthServiceProxy, JSONRPCException\n\nrpc_user = 'dein_rpc_benutzername'\nrpc_password = 'dein_rpc_passwort'\nrpc_port = 'port_des_nodes'  # Standardport ist 18443 f\u00fcr regtest\n\nrpc_connection = AuthServiceProxy(f'http://{rpc_user}:{rpc_password}@127.0.0.1:{rpc_port}')\n\n# Beispielaufrufe\ntry:\n    info = rpc_connection.getinfo()\n    balance = rpc_connection.getbalance()\n    new_address = rpc_connection.getnewaddress()\n    \n    print(\"Node Info:\", info)\n    print(\"Balance:\", balance)\n    print(\"New Address:\", new_address)\n\nexcept JSONRPCException as e:\n    print(\"Error:\", e.error['message'])\n"
  },
  {
    "type": "c",
    "code": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <unistd.h>\n#include <arpa/inet.h>\n\n#define SERVER_IP \"127.0.0.1\" // \uc11c\ubc84 IP \uc8fc\uc18c\n#define PORT 3001\n#define BUFFER_SIZE 258 // \ucd5c\ub300 \ub370\uc774\ud130 \ud06c\uae30\n\nint main() {\n    int client_socket;\n    struct sockaddr_in server_addr;\n    char buffer[BUFFER_SIZE]; // \ub370\uc774\ud130\ub97c \uc800\uc7a5\ud560 \ubc84\ud37c\n    int flag, c;\n\n    // Create socket\n    if ((client_socket = socket(AF_INET, SOCK_DGRAM, 0)) < 0) {\n        perror(\"socket creation failed\");\n        exit(EXIT_FAILURE);\n    }\n\n    memset(&server_addr, 0, sizeof(server_addr));\n\n    // Configure server address\n    server_addr.sin_family = AF_INET;\n    server_addr.sin_port = htons(PORT);\n    if (inet_pton(AF_INET, SERVER_IP, &server_addr.sin_addr) <= 0) {\n        perror(\"inet_pton failed\");\n        exit(EXIT_FAILURE);\n    }\n\n    while (1) {\n        do {\n            flag = 0;\n            printf(\"Client (You): \");\n            if (!fgets(buffer, sizeof(buffer), stdin)) {\n                printf(\"\uc785\ub825 \uc624\ub958\uac00 \ubc1c\uc0dd\ud558\uc600\uc2b5\ub2c8\ub2e4.\\n\");\n                flag = 1;\n                continue;\n            }\n            buffer[strcspn(buffer, \"\\n\")] = '\\0'; // \uc904\ubc14\uafc8 \ubb38\uc790 \uc81c\uac70\n            int send_result = sendto(client_socket, buffer, strlen(buffer) + 1, 0, (const struct sockaddr *)&server_addr, sizeof(server_addr));\n            if (send_result < 0) {\n                perror(\"sendto failed\");\n                flag = 1;\n            }\n        } while (flag);\n\n        // Receive data from server\n        ssize_t received_bytes = recvfrom(client_socket, buffer, sizeof(buffer), 0, NULL, NULL);\n        if (received_bytes < 0) {\n            perror(\"recvfrom failed\");\n            continue;\n        }\n\n        // Print the received data in hexadecimal format\n        printf(\"Server: \");\n        for (ssize_t i = 0; i < received_bytes; i++) {\n            printf(\"%02x \", (unsigned char)buffer[i]);\n        }\n        printf(\"\\n\");\n    }\n\n    close(client_socket);\n    return 0;\n}\n"
  },
  {
    "type": "javascript",
    "code": "// Utilities\nimport { createPinia } from 'pinia'\nimport axios from 'axios'\n\naxios.defaults.baseURL = process.env.baseURL || 'http://localhost:3000'\naxios.defaults.withCredentials = true\n\nexport default function () {\n  const pinia = createPinia()\n\n  // Burada istedi\u011finiz kodu \u00e7al\u0131\u015ft\u0131rabilirsiniz.\n  console.log(\"Pinia olu\u015fturuldu.\")\n\n  return pinia\n}\n"
  },
  {
    "type": "javascript",
    "code": "const dgram = require('dgram');\n\n// create a PCP request packet\nconst buf = Buffer.alloc(60);\nbuf.writeUInt8(2, 0); // version\nbuf.writeUInt8(0, 1); // opcode (MAP)\nbuf.writeUInt16BE(0, 2); // reserved\nbuf.writeUInt16BE(0, 4); // result code\nbuf.writeUInt32BE(7200, 6); // lifetime\nbuf.write(\"::ffff:192.0.2.33\", 10); // client IP address\nbuf.writeUInt8(6, 26); // protocol (TCP)\nbuf.writeUInt16BE(0, 27); // reserved\nbuf.writeUInt16BE(12345, 30); // internal port\nbuf.writeUInt16BE(12345, 32); // suggested external port\nbuf.write(\"::ffff:203.0.113.1\", 34); // suggested external IP address\n\nconst client = dgram.createSocket('udp4');\n\nclient.send(buf, 5351, '192.168.1.1', (err) => {\n  if (err) console.log(err);\n  client.close();\n});\n"
  },
  {
    "type": "javascript",
    "code": "const elements = document.querySelectorAll('.myClass');\n"
  },
  {
    "type": "python",
    "code": "CRONJOBS = [\n    ('0 0 * * *', 'myapp.cron.reset_levels')\n]\n"
  },
  {
    "type": "python",
    "code": "import numpy\nprint(numpy.__version__)\n"
  },
  {
    "type": "java",
    "code": "import org.springframework.beans.factory.annotation.Value;\n\n// ...\n\n@Value(\"${OPENAI_API_KEY}\")\nprivate String apiKey;\n"
  },
  {
    "type": "python",
    "code": "# Copyright (c) 2023 Your Name. All rights reserved.\n\nimport hashlib\nfrom typing import List\n\n# Define FS1R specific addresses and other constants\nSYSTEM_SETTINGS_ADDRESS_FS1R = (0x00, 0x00, 0x00)  # Placeholder, adjust based on FS1R spec\n\ndef name():\n    return \"Yamaha FS1R adaption\"\n\ndef createDeviceDetectMessage(channel):\n    # Modify this to send a request specific to FS1R\n    return buildRequestFS1R(channel, SYSTEM_SETTINGS_ADDRESS_FS1R)\n\ndef isOwnSysex(message):\n    # Check if the message is a sysex message for the FS1R\n    if (len(message) > 7\n            and message[0] == 0xf0  # Sysex\n            and message[1] == 0x43  # Yamaha\n            # Add more conditions based on FS1R spec\n       ):\n        return True\n    return False\n\ndef nameFromDump(message):\n    # Extract the name of the patch from the FS1R sysex dump\n    # Placeholder, adjust based on FS1R spec\n    return \"Placeholder Name\"\n\ndef renamePatch(message, new_name):\n    # Rename a patch on the FS1R\n    # Placeholder, adjust based on FS1R spec\n    return message\n\n# Add more FS1R-specific functions...\n\ndef buildRequestFS1R(channel, address):\n    # Build a request message for FS1R\n    # Placeholder, adjust based on FS1R spec\n    return [0xf0, 0x43, 0x20 | (channel & 0x0f), 0x7f, 0x1c, 0x05, address[0], address[1], address[2]] + [0xf7]\n\n# Add utility functions to handle FS1R sysex messages, data parsing, etc.\n\n# ...\n\ndef make_test_data():\n    # For testing the FS1R adaptation\n    # Placeholder, adjust based on FS1R spec and testing needs\n    pass\n"
  },
  {
    "type": "javascript",
    "code": "// ==UserScript==\n// @name         Twitter Redirect to Media Timeline\n// @namespace    http://your.namespace.here\n// @version      0.1\n// @description  Redirects Twitter profile link clicks and location changes to media timeline, excluding media timeline itself and internal pages.\n// @author       Your Name\n// @match        https://twitter.com/*\n// @grant        none\n// ==/UserScript==\n\n(function() {\n    'use strict';\n\n    // Function to check if the URL belongs to a media timeline\n    function isMediaTimeline(url) {\n        return url.includes('/media');\n    }\n\n    // Function to check if the URL is an internal Twitter page\n    function isInternalPage(url) {\n        return url.includes('/settings/') || url.includes('/messages') || /* Add more if needed */;\n    }\n\n    // Function to check if the URL points to a user profile\n    function isUserProfile(url) {\n        const profileMatch = url.match(/twitter\\.com\\/([^/?]+)$/);\n        return profileMatch && !isMediaTimeline(url) && !isInternalPage(url);\n    }\n\n    // Function to handle redirection\n    function redirectIfNeeded(url) {\n        if (isUserProfile(url)) {\n            const username = url.match(/twitter\\.com\\/([^/?]+)$/)[1];\n            const redirectURL = `https://twitter.com/${username}/media`;\n            window.location.href = redirectURL;\n        }\n    }\n\n    // Attach click event listener to all profile links\n    const profileLinks = document.querySelectorAll('a[href*=\"/twitter.com/\"]');\n    profileLinks.forEach(link => {\n        link.addEventListener('click', event => {\n            redirectIfNeeded(link.getAttribute('href'));\n            event.preventDefault();\n        });\n    });\n\n    // Listen for window location changes\n    const oldPushState = history.pushState;\n    history.pushState = function() {\n        oldPushState.apply(history, arguments);\n        redirectIfNeeded(window.location.href);\n    };\n})();\n"
  },
  {
    "type": "javascript",
    "code": "tablist.find('a').filter(function() {\n    return $.trim($(this).text()) === \"Sub-tasks\";\n}).click();\n"
  },
  {
    "type": "javascript",
    "code": "const arr1 = { 'key1': 'value1', 'key2': 'value2' };\nconst arr2 = { 'key1': 'newValue1', 'key3': 'newValue3' };\n\n// Merge the two objects\nconst mergedObj = { ...arr1, ...arr2 };\n\n// Convert the merged object to a JSON string\nconst jsonString = JSON.stringify(mergedObj);\n\nconsole.log(jsonString);\n"
  },
  {
    "type": "javascript",
    "code": "const { PrismaClient } = require('@prisma/client');\nconst notp = require('notp');\nconst prisma = new PrismaClient();\n\nmodule.exports = {\n  createTOTP: async function (verificationTarget, type) {\n    const secretKey = generateSecretKey(); // function to generate your secret key\n\n    // Delete any existing verification for this target and type\n    await prisma.verification.deleteMany({\n      where: {\n        verificationTarget,\n        type,\n      },\n    });\n\n    const otp = notp.totp.gen(secretKey);\n    const expirationTime = calculateExpirationTime(); // function to calculate the expiration time\n\n    // Create a new verification record\n    const newVerification = await prisma.verification.create({\n      data: {\n        verificationTarget,\n        type,\n        secretKey,\n        otp,\n        expirationTime,\n      },\n    });\n\n    return otp;\n  },\n\n  verifyTOTP: async function (verificationTarget, type, otp) {\n    // Get the verification record\n    const verification = await prisma.verification.findUnique({\n      where: {\n        verificationTarget_type: {\n          verificationTarget,\n          type,\n        },\n      },\n    });\n\n    if (!verification) {\n      throw new Error('Verification record not found');\n    }\n\n    // Check if OTP is valid\n    const isOTPValid = notp.totp.verify(otp, verification.secretKey);\n\n    if (!isOTPValid) {\n      throw new Error('Invalid OTP');\n    }\n\n    // Check if OTP is expired\n    const currentTime = new Date();\n    if (currentTime > verification.expirationTime) {\n      throw new Error('Expired OTP');\n    }\n\n    // If OTP is valid and not expired, delete the verification record\n    await prisma.verification.delete({\n      where: {\n        verificationTarget_type: {\n          verificationTarget,\n          type,\n        },\n      },\n    });\n\n    return true;\n  },\n};\n\n// These are placeholder functions. Replace these with your actual implementation.\n\nfunction generateSecretKey() {\n  // Replace this with your actual secret key generation logic\n  return 'some-secret-key';\n}\n\nfunction calculateExpirationTime() {\n  // Replace this with your actual expiration time calculation logic\n  return new Date();\n}\n"
  },
  {
    "type": "ruby",
    "code": "# config/integration.rb\n\nRails.application.configure do\n  # Configuration specific to the integration environment\n  # ...\nend\n"
  },
  {
    "type": "python",
    "code": "import asyncio\nimport ijson\n\nasync def remove_keys(obj):\n    \"\"\"Asynchronously remove keys starting with '_' from an object\"\"\"\n    if isinstance(obj, dict):\n        return {k: await remove_keys(v) for k, v in obj.items() if not k.startswith('_')}\n    elif isinstance(obj, list):\n        return [await remove_keys(item) for item in obj]\n    else:\n        return obj\n\nasync def transform_json(json_stream):\n    parser = ijson.parse_async(json_stream)\n    items = ijson.items_async(parser, 'item')\n\n    async for item in items:\n        yield await remove_keys(item)\n\nasync def test():\n    async def json_stream():\n        chunks = [\n            b'{\"item\": {\"_id\": 1, \"name\": \"test1\"}},',\n            b'{\"item\": {\"_id\": 2, \"name\": \"test2\"}},',\n            b'{\"item\": {\"_id\": 3, \"name\": \"test3\"}}'\n        ]\n        for chunk in chunks:\n            yield chunk\n            await asyncio.sleep(0.1)\n\n    async for transformed_item in transform_json(json_stream()):\n        print(transformed_item)\n\n# Run the test coroutine\nasyncio.run(test())\n"
  },
  {
    "type": "c",
    "code": "float4 val0 = read_imagef(data1, smp, (int2)(lidx0-1,0));\n"
  },
  {
    "type": "javascript",
    "code": "const Aria2 = require('aria2') // Assuming you're using a Node.js aria2 library\n\nclass Torrent extends EventEmitter {\n  constructor (opts) {\n    // Existing code...\n\n    // Check for aria2c RPC switch\n    if (opts.useAria2c) {\n      this._setupAria2c(opts)\n    }\n  }\n\n  // Other existing methods...\n\n  _setupAria2c (opts) {\n    // Check if aria2c binary is available on the path\n    if (!this._checkAria2cBinary()) {\n      throw new Error('aria2c binary not found')\n    }\n\n    // Initialize aria2c\n    this.aria2 = new Aria2({\n      host: opts.aria2Host,\n      port: opts.aria2Port,\n      secure: opts.aria2Secure,\n      secret: opts.aria2Secret,\n      path: opts.aria2Path\n    })\n\n    // Replace default components with aria2c equivalents\n    this.server = new Aria2cServer(this, opts) // Assuming you've created an Aria2cServer class\n    this.swarm = new Aria2cSwarm(this, opts) // Assuming you've created an Aria2cSwarm class\n    this.tracker = new Aria2cTracker(this, opts) // Assuming you've created an Aria2cTracker class\n    this.peer = new Aria2cPeer(this, opts) // Assuming you've created an Aria2cPeer class\n  }\n\n  _checkAria2cBinary () {\n    // Implement a method to check if the aria2c binary is available on the path\n    // This could involve running a command like 'aria2c --version' and checking the result\n  }\n\n  // Other existing methods...\n}\n"
  },
  {
    "type": "javascript",
    "code": "// pages/api/protected.js\n\nimport { getSession } from 'next-auth/react';\nimport connectToDatabase from '../../db';\n\nexport default async function handler(req, res) {\n  const session = await getSession({ req });\n\n  if (!session) {\n    res.status(401).json({ error: 'Unauthorized' });\n    return;\n  }\n\n  // Use the session.user.id to query the database or perform other actions\n\n  res.status(200).json({ message: 'You are authorized' });\n}\n"
  },
  {
    "type": "python",
    "code": "from joblib import Parallel, delayed\n\ndef process_data(data):\n    # Process the data here\n    return processed_data\n\nif __name__ == '__main__':\n    # Input data\n    data = [...]\n\n    # Parallelize the processing of data\n    results = Parallel(n_jobs=-1)(delayed(process_data)(item) for item in data)\n\n    # Process the results\n    for result in results:\n        # Process the result here\n"
  },
  {
    "type": "python",
    "code": "from urllib.parse import urlparse\n\n@classmethod\ndef from_text(cls, text: str) -> \"OpenAPISpec\":\n    \"\"\"Get an OpenAPI spec from a text.\"\"\"\n    try:\n        spec_dict = json.loads(text)\n    except json.JSONDecodeError:\n        spec_dict = yaml.safe_load(text)\n\n    # Parse the URL\n    parsed_url = urlparse(text)\n\n    # Construct the root URL\n    root_url = f\"{parsed_url.scheme}://{parsed_url.netloc}\"\n\n    if \"servers\" not in spec_dict:\n        spec_dict[\"servers\"] = [{\"url\": root_url}] # Using the root_url\n\n    print(\"spec_dict: \", json.dumps(spec_dict, indent=2))\n    print(\"openapi_url: \", text)\n    print(\"root_url: \", root_url) # Printing the root_url\n    return cls.from_spec_dict(spec_dict)\n"
  },
  {
    "type": "python",
    "code": "import hashlib\n\n# Define constants\nID_SIZE = 16\n\nclass Record:\n    def __init__(self, timestamp, id):\n        self.timestamp = timestamp\n        self.id = id[:ID_SIZE]\n\n    def fingerprint(self):\n        return hashlib.md5(self.id.encode()).digest()[:ID_SIZE]\n\nclass Range:\n    def __init__(self, lower_bound, upper_bound, mode, payload):\n        self.lower_bound = lower_bound\n        self.upper_bound = upper_bound\n        self.mode = mode\n        self.payload = payload\n\n    def split(self, num_splits):\n        \"\"\"Split the range into smaller ranges (if applicable).\"\"\"\n        # This is a basic implementation that equally divides the range\n        split_ranges = []\n        interval = (self.upper_bound.timestamp - self.lower_bound.timestamp) // num_splits\n        for i in range(num_splits):\n            new_lower = self.lower_bound.timestamp + i * interval\n            new_upper = new_lower + interval\n            split_ranges.append(Range(new_lower, new_upper, \"Fingerprint\", None))\n        return split_ranges\n\ndef generate_fingerprint(records):\n    \"\"\"Generate a fingerprint for a range of records.\"\"\"\n    combined = b\"\".join([record.fingerprint() for record in records])\n    return hashlib.md5(combined).digest()[:ID_SIZE]\n\ndef reconcile(client_records, server_records):\n    \"\"\"Main reconciliation function.\"\"\"\n    # Initially, let's assume client initiates the reconciliation\n    client_ranges = [Range(0, float('inf'), \"Fingerprint\", None)]\n\n    # Start reconciliation loop\n    for client_range in client_ranges:\n        # If mode is Fingerprint, compare fingerprints\n        if client_range.mode == \"Fingerprint\":\n            client_fingerprint = generate_fingerprint(client_records)\n            server_fingerprint = generate_fingerprint(server_records)\n            \n            if client_fingerprint != server_fingerprint:\n                # Split range and continue\n                client_ranges.extend(client_range.split(2))\n            else:\n                # No reconciliation needed for this range\n                pass\n        elif client_range.mode == \"IdList\":\n            # More advanced logic for IdList and IdListResponse would go here\n            pass\n\n    # After loop, you'd have fully reconciled ranges\n    # This is a very basic approach and needs more detailed logic for full functionality\n\n# Sample records for testing\nclient_records = [Record(1, \"abcd\"), Record(2, \"efgh\"), Record(3, \"ijkl\")]\nserver_records = [Record(1, \"abcd\"), Record(2, \"efgh\"), Record(4, \"mnop\")]\n\n# Initiate reconciliation\nreconcile(client_records, server_records)\n"
  },
  {
    "type": "javascript",
    "code": "window.addEventListener('popstate', function(event) {\n  if (!confirm('Are you sure you want to navigate away?')) {\n    // Restore the previous state to prevent navigation\n    history.pushState(null, null, event.state ? event.state : '');\n  }\n});\n"
  },
  {
    "type": "python",
    "code": "@app.route('/eval/tentative', methods=['GET'])\ndef evaluate_tentative():\n    try:\n        # Retrieve the plugin_name or root_url from the request parameters\n        plugin_name = request.args.get('plugin_name')\n        root_url = request.args.get('root_url')\n\n        # Ensure that either plugin_name or root_url is provided\n        if not plugin_name and not root_url:\n            return jsonify({\"error\": \"Either plugin_name or root_url must be provided\"}), 400\n\n        # Initialize the plugin\n        try:\n            if plugin_name:\n                plugin = open_plugin_memo.get_plugin(plugin_name)\n            elif root_url:\n                plugin = open_plugin_memo.init_openplugin(root_url=root_url)\n        except:\n            return jsonify({\"error\": \"Failed to initialize the plugin. It might not be whitelisted.\"}), 400\n\n        # Ensure the plugin was initialized successfully\n        if not plugin:\n            return jsonify({\"error\": \"Failed to initialize the plugin.\"}), 400\n\n        # Retrieve the manifest from the plugin\n        manifest = plugin.manifest\n\n        # Extract the relevant openplugin_info values from the manifest\n        openplugin_info = {\n            \"namespace\": plugin_name or root_url,\n            \"description_for_human\": manifest.get(\"description_for_human\"),\n            \"description_for_model\": manifest.get(\"description_for_model\"),\n            \"domain\": plugin.root_url,\n            \"auth\": manifest.get(\"auth\", False),\n            \"blacklisted\": False,\n            \"whitelisted\": True,\n            \"stimulous_prompt\": manifest.get(\"name_for_model\"),\n            \"stimulated\": False,\n            \"status\": \"tentative\",\n            \"js_info\": {\n                \"whitelisted\": False,\n                \"stimulated\": False,\n                \"status\": \"unsupported\"\n            }\n        }\n\n        # Ensure all required values are present in the openplugin_info\n        required_keys = [\"namespace\", \"description_for_human\", \"description_for_model\", \"domain\", \"auth\"]\n        for key in required_keys:\n            if not openplugin_info.get(key):\n                return jsonify({\"error\": f\"Missing value for {key} in the manifest.\"}), 400\n\n        return jsonify(openplugin_info), 200\n\n    except Exception as e:\n        error_class = type(e).__name__\n        error_message = str(e)\n        return jsonify({\"error\": f\"{error_class} error: {error_message}\"}), 500\n"
  },
  {
    "type": "python",
    "code": "@app.route('/oauth_token', methods=['GET'])\ndef oauth_token():\n    try:\n        # Extract the state and code parameters\n        state = request.args.get('state')\n        code = request.args.get('code')\n\n        # Retrieve the session using the state\n        session_data = session.get(state)\n        if not session_data:\n            return jsonify({\"error\": \"Invalid state\"}), 400\n\n        # Fetch the item from the 'openplugin-auth' collection using the client_domain\n        item = db[\"openplugin-auth\"].find_one({\"domain\": session_data[\"client_domain\"]})\n        if not item:\n            return jsonify({\"error\": \"Item not found\"}), 404\n\n        # Retrieve the client_secret from the item\n        client_secret = item.get(\"oauth\", {}).get(\"client_secret\")\n        if not client_secret:\n            return jsonify({\"error\": \"Client secret not found\"}), 404\n\n        # Initialize the client with the provided client_id\n        client = WebApplicationClient(session_data[\"client_id\"])\n\n        # Prepare the token request\n        token_request_headers = {\n            \"Content-Type\": session_data[\"authorization_content_type\"]\n        }\n        token = client.prepare_token_request(\n            session_data[\"token_url\"],\n            authorization_response=request.url,\n            redirect_url=f\"{request.url_root.rstrip('/')}/oauth_token\",\n            client_id=session_data[\"client_id\"],\n            client_secret=client_secret\n        )\n        token_url, headers, data_string = token\n\n        # Conditional handling based on content type\n        data_dict = dict([pair.split('=') for pair in data_string.split('&')])\n        if token_request_headers[\"Content-Type\"] == \"application/x-www-form-urlencoded\":\n            token_data = urllib.parse.urlencode(data_dict)\n        elif token_request_headers[\"Content-Type\"] == \"application/json\":\n            token_data = json.dumps(data_dict)\n\n        # Make the POST request to the token_url\n        token_response = requests.post(\n            token_url,\n            headers=token_request_headers,\n            data=token_data\n        )\n\n        # Parse the response data\n        client.parse_request_body_response(json.dumps(token_response.json()))\n\n        # Construct the redirect URL with the response data and other parameters\n        params = {\n            **token_response.json(),\n            \"client_domain\": session_data[\"client_domain\"],\n            \"oauth_token\": \"true\"\n        }\n        redirect_url = f\"{session_data['openplugin_callback_url']}?{urllib.parse.urlencode(params)}\"\n\n        return redirect(redirect_url)\n\n    except Exception as e:\n        error_class = type(e).__name__\n        error_message = str(e)\n        return jsonify({\"error\": f\"{error_class} error: {error_message}\"}), 500\n"
  },
  {
    "type": "python",
    "code": "import requests\nimport json\n\n# API endpoints\nget_url = \"https://openlibrary.org{work_key}/editions.json\"\nput_url = \"https://openlibrary.org{ol_key}.json\"\n\n# Dry run option\ndry_run = True  # Set to False to actually make changes\n\n# Read the work keys from file\nwith open('works-null-lccn.txt', 'r') as file:\n    work_keys = [line.strip() for line in file]\n\nfor work_key in work_keys:\n    # fetch the list of editions for the current work_key\n    response = requests.get(get_url.format(work_key=work_key))\n\n    if response.status_code == 200:\n        data = response.json()\n\n        for entry in data['entries']:\n            if 'lccn' in entry and entry['lccn'] == [None]:\n                # If dry_run is True, just print the changes\n                if dry_run:\n                    print(f\"Would remove lccn from {entry['key']}\")\n                else:\n                    # remove the lccn field\n                    del entry['lccn']\n\n                    # update the edition record\n                    update_response = requests.put(put_url.format(ol_key=entry['key']), json=entry)\n\n                    if update_response.status_code != 200:\n                        print(f\"Failed to update {entry['key']}\")\n    else:\n        print(f\"Failed to get editions for {work_key}\")\n"
  },
  {
    "type": "c",
    "code": "rustup component add rust-std=\ubc84\uc804\n"
  },
  {
    "type": "python",
    "code": "def tree_to_html(tree):\n    html = '<ul>\\n'\n    for depth, name, children in tree:\n        html += f'    <li>{depth}: {name.capitalize()}'\n        if children:\n            html += '\\n' + tree_to_html(children) + '    '\n        html += '</li>\\n'\n    html += '</ul>'\n    return html\n"
  },
  {
    "type": "javascript",
    "code": "<template>\n  <div>\n    <button @click=\"generateJWT\">Generate JWT</button>\n    <div v-if=\"token\">{{ token }}</div>\n  </div>\n</template>\n\n<script>\nimport axios from 'axios';\n\nexport default {\n  data() {\n    return {\n      token: '',\n    };\n  },\n  methods: {\n    generateJWT() {\n      axios.get('/generate-jwt')\n        .then(response => {\n          this.token = response.data.token;\n        })\n        .catch(error => {\n          console.error(error);\n        });\n    },\n  },\n};\n</script>\n"
  },
  {
    "type": "javascript",
    "code": "// src/lib/api.js\nexport async function getIssueComments(owner, repo, issueNumber) {\n    const response = await fetch(`https://api.github.com/repos/${owner}/${repo}/issues/${issueNumber}/comments`);\n    if (!response.ok) {\n        throw new Error('Failed to fetch comments');\n    }\n    return response.json();\n}\n"
  },
  {
    "type": "python",
    "code": "from hdscraper.product_details.product_details_scraper import (\n    ApiSession, ProductDetailsScraper)\n"
  },
  {
    "type": "javascript",
    "code": "|> list(events) |> log:format=json |> wrapWith(code block)\n"
  },
  {
    "type": "python",
    "code": "from PIL import Image\n\ndef enlarge_image(image_path, new_width, new_height):\n    # Open the image\n    image = Image.open(image_path)\n\n    # Calculate the width and height difference\n    width, height = image.size\n    width_diff = new_width - width\n    height_diff = new_height - height\n\n    # Create a new blank image with the desired size\n    new_image = Image.new(\"RGB\", (new_width, new_height), \"white\")\n\n    # Calculate the left padding\n    left_padding = width_diff\n\n    # Paste the original image onto the new image with padding\n    new_image.paste(image, (left_padding, 0))\n\n    # Save the enlarged image\n    new_image.save(\"enlarged_icon.png\")\n\n    print(\"Image enlarged and saved as 'enlarged_icon.png'.\")\n\n# Specify the path to the original image and the desired new dimensions\nimage_path = \"icon.png\"\nnew_width = 225\nnew_height = 225\n\n# Call the function to enlarge the image\nenlarge_image(image_path, new_width, new_height)\n"
  },
  {
    "type": "python",
    "code": "def generate_abbreviated_highlight(actor, verb, object_):\n    return f\"{actor} {verb} {object_}.\"\n\n# Initialize a dictionary to store summarized activities\nsummarized_activities = {}\n\n# Example list of activities (replace this with your actual activity data)\nactivities = [\n    {\"actor\": \"UserA\", \"verb\": \"liked\", \"object\": \"your post\"},\n    {\"actor\": \"UserB\", \"verb\": \"liked\", \"object\": \"your post\"},\n    # Add more activities here\n]\n\n# Summarize the activities\nfor activity in activities:\n    actor = activity[\"actor\"]\n    verb = activity[\"verb\"]\n    object_ = activity[\"object\"]\n    \n    if (actor, verb, object_) in summarized_activities:\n        summarized_activities[(actor, verb, object_)] += 1\n    else:\n        summarized_activities[(actor, verb, object_)] = 1\n\n# Generate and print the summarized highlights\nfor (actor, verb, object_), count in summarized_activities.items():\n    highlight = generate_abbreviated_highlight(actor, verb, object_)\n    if count > 1:\n        print(f\"{highlight} ({count} times)\")\n    else:\n        print(highlight)\n"
  },
  {
    "type": "python",
    "code": "'def find_symbol_nodes(code: str, symbols: Iterable[str]) -> List[Tuple[AST, Optional[str]]]'\n"
  },
  {
    "type": "python",
    "code": "import sqlite3\n\n# Open connection to the new database\nnew_db = sqlite3.connect('favorites.db')\n\n# Attach the old database to the new database\nnew_db.execute(\"ATTACH DATABASE 'favorites old.db' AS old_db\")\n\n# Assuming the structure of the favorites table is (id, favorite_item),\n# where id is a unique identifier for each row.\nnew_db.execute(\"\"\"\n    INSERT INTO favorites (id, favorite_item)\n    SELECT id, favorite_item FROM old_db.favorites\n    WHERE (id, favorite_item) NOT IN (SELECT id, favorite_item FROM favorites)\n\"\"\")\n\n# Commit changes and close the connection\nnew_db.commit()\nnew_db.close()\n"
  },
  {
    "type": "python",
    "code": "print(f\"The distance between {args.airport1} and {args.airport2} is {distance:.2f} miles.\")\n"
  },
  {
    "type": "javascript",
    "code": "(function() {\n    // Backup the original fetch function\n    const originalFetch = window.fetch;\n    let allPlugins = [];\n    let totalCount = 0;\n    let fetchedCount = 0;\n\n    // Override the fetch function\n    window.fetch = async function(...args) {\n        const response = await originalFetch.apply(this, args);\n        if (args[0].includes('https://chat.openai.com/backend-api/aip/p/approved')) {\n            const responseData = await response.clone().json();\n            if (responseData && responseData.items) {\n                allPlugins = allPlugins.concat(responseData.items);\n                fetchedCount += responseData.items.length;\n                if (responseData.count) {\n                    totalCount = responseData.count;\n                }\n                if (fetchedCount < totalCount) {\n                    // Simulate a click on the \"Next\" button to fetch the next page\n                    let nextButton = Array.from(document.querySelectorAll('button[role=\"button\"]')).find(btn => btn.textContent.includes('Next') && btn.querySelector('svg'));\n                    if (nextButton) {\n                        nextButton.click();\n                    }\n                } else {\n                    console.log(allPlugins); // All plugins have been fetched\n                }\n            }\n        }\n        return response;\n    };\n\n    // Function to click the \"All\" button\n    function clickAllButton() {\n        let buttons = document.querySelectorAll('button');\n        let allButton = Array.from(buttons).find(btn => btn.textContent.trim() === 'All');\n        if (allButton) {\n            allButton.click();\n        }\n    }\n\n    // Execute the clickAllButton function to start the process\n    clickAllButton();\n\n})();\n"
  },
  {
    "type": "python",
    "code": "def redirect_werkzeug_logs_to_loguru(record):\n    log_level = logging.getLevelName(record.levelno)\n    logger_opt = logger.opt(depth=6, exception=record.exc_info)\n    logger_opt.log(log_level, record.getMessage())\n"
  },
  {
    "type": "c",
    "code": "#include \"path/to/first_lib.h\"\n"
  },
  {
    "type": "javascript",
    "code": "function removeAttributesFromDOM(element) {\n  var attributes = element.attributes;\n  for (var i = attributes.length - 1; i >= 0; i--) {\n    var attributeName = attributes[i].name;\n    if (\n      attributeName !== \"id\" &&\n      attributeName !== \"class\" &&\n      attributeName !== \"content\" &&\n      attributeName !== \"name\"\n    ) {\n      element.removeAttribute(attributeName);\n    }\n  }\n}\n\n// \u4f7f\u7528\u4f8b\nvar targetElement = document.getElementById(\"targetElementId\");\nremoveAttributesFromDOM(targetElement);\n"
  },
  {
    "type": "javascript",
    "code": "class TokenBucket {\n    protected tokens: number;\n    protected lastRefillTimestamp: number;\n\n    constructor(protected capacity: number, protected refillRate: number) {\n        this.tokens = capacity;\n        this.lastRefillTimestamp = performanceNow();\n    }\n\n    protected refill() {\n        const now = performanceNow();\n        const elapsedTime = (now - this.lastRefillTimestamp) / 1000; // Convert to seconds\n\n        const refillTokens = Math.floor(elapsedTime * this.refillRate);\n        this.tokens = Math.min(this.tokens + refillTokens, this.capacity);\n\n        this.lastRefillTimestamp = now;\n    }\n\n    consume(tokensToConsume: number = 1): boolean {\n        this.refill();\n\n        if (this.tokens >= tokensToConsume) {\n            this.tokens -= tokensToConsume;\n            return true;\n        }\n        return false;\n    }\n}\n\nclass RateLimiter {\n    private tokenBuckets: Map<string, TokenBucket>;\n\n    constructor() {\n        this.tokenBuckets = new Map();\n    }\n\n    // Retrieve or create a new bucket for a given key\n    getBucket(key: string, capacity: number, refillRate: number): TokenBucket {\n        if (!this.tokenBuckets.has(key)) {\n            this.tokenBuckets.set(key, new TokenBucket(capacity, refillRate));\n        }\n        return this.tokenBuckets.get(key)!;\n    }\n\n    consume(key: string, tokensToConsume: number = 1): boolean {\n        const bucket = this.tokenBuckets.get(key);\n        if (!bucket) {\n            throw new Error(`TokenBucket for key '${key}' not found. Make sure to initialize it first with getBucket().`);\n        }\n        return bucket.consume(tokensToConsume);\n    }\n}\n\n// Example Usage:\nconst rateLimiter = new RateLimiter();\n\n// Initialize a specific bucket\nrateLimiter.getBucket('someAction', 1, 0.2);\n\n// Try consuming a token for a specific action\nif (rateLimiter.consume('someAction')) {\n    console.log('Token consumed, perform the action!');\n} else {\n    console.log('Rate limit exceeded for someAction. Try again later.');\n}\n"
  },
  {
    "type": "python",
    "code": "@site.register()\ndef List(url):\n    total_videos = 0\n    video_list = []\n    next_url = url\n\n    while total_videos < 30 and next_url:\n        try:\n            listhtml = utils.getHtml(next_url, '')\n        except:\n            return None\n\n        match = re.compile(r'bg-black\"><a href=\"([^\"]+).+?<img\\s*src=\"([^\"]+).+?<div class=\"videoDur\">([:\\d]+).+?<div class=\"videoTtl\" title=\"([^\"]+).*?redirect-link\">([^<]+)', re.DOTALL | re.IGNORECASE).findall(listhtml)\n        for videopage, img, duration, name, nice in match:\n            # Check video duration and continue if less than 15 min\n            dur_min = sum(x * int(t) for x, t in zip([60, 1, 1/60], duration.split(\":\")))\n            if dur_min < 15:\n                continue\n            \n            nice = \" [COLOR lime][\" + nice + \"][/COLOR]\"\n            name = utils.cleantext(name).title()\n\n            contexturl = (utils.addon_sys + \"?mode=custom_eroprofile_by_Cumination.Lookupinfo&list_mode=custom_eroprofile_by_Cumination.List&url=\" + urllib_parse.quote_plus(BASE_URL + videopage))\n            contextmenu = [\n                (\n                    '[COLOR deeppink]Lookup info[/COLOR]',\n                    'RunPlugin(' + contexturl + ')',\n                )\n            ]\n            # Add to temporary list\n            video_list.append((name + nice, BASE_URL + videopage, 'Playvid', img, name + nice, duration, contextmenu))\n            total_videos += 1\n\n        nextp = re.compile('([^\\\"]+)\\\"\\D*21_73').search(listhtml)\n        next_url = BASE_URL + nextp[1].replace('&amp;', '&') if nextp else None\n\n    # Add video links to Kodi\n    for video in video_list:\n        site.add_download_link(*video)\n        \n    if next_url:\n        np = int(re.compile('(\\d+)\\\"\\D*21_73').search(listhtml)[1])\n        cp = np - 1\n        lp = re.compile(r'(\\d+)\\\"\\D+21_75').search(listhtml)[1]\n        nplptxt = 'Next Page (' + str(cp) + ' / ' + str(lp) + ')'\n\n        cm_page = (utils.addon_sys + \"?mode=custom_eroprofile_by_Cumination.GotoPage&list_mode=custom_eroprofile_by_Cumination.List&url=\" + urllib_parse.quote_plus(next_url) + \"&np=\" + str(np) + \"&lp=\" + str(lp))\n        cm = [('[COLOR violet]Goto Page #[/COLOR]', 'RunPlugin(' + cm_page + ')')]\n        site.add_dir(nplptxt, next_url, 'List', site.img_next, contextm=cm)\n\n    utils.eod()\n"
  },
  {
    "type": "python",
    "code": "class ProjectTask(models.Model):\n    _inherit = 'project.task'\n\n    sub_tasks_count = fields.Integer(compute='_compute_sub_tasks_count')\n\n    @api.depends('sub_tasks')\n    def _compute_sub_tasks_count(self):\n        for task in self:\n            task.sub_tasks_count = len(task.sub_tasks)\n"
  },
  {
    "type": "python",
    "code": "import openai\nimport command_manager\nimport voice_feedback\n\nbot = None  # the ChatGPT bot object\nopenai.api_key = 'your-api-key'  # replace 'your-api-key' with your actual OpenAI API key\n\ndef chat(text):\n    \"\"\"\n    handles user-chatgpt interactions\n    \"\"\"\n    if command_manager.hasText(text, command_manager.deactivateChatMode):\n        voice_feedback.speak('deactivating chatgpt mode', wait=True)\n        command_manager.chatMode = False\n        return\n    global bot\n    if not bot:\n        try:\n            bot = openai.ChatCompletion.create(\n                model=\"gpt-3.5-turbo\",\n                messages=[\n                    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n                    {\"role\": \"user\", \"content\": text}\n                ]\n            )\n        except Exception as e:\n            print(e)\n    print(f\"You to ChatGPT: {text}\")\n    response = bot['choices'][0]['message']['content']\n    voice_feedback.speak(response, wait=True)\n"
  },
  {
    "type": "python",
    "code": "# Set the mask value for the first eos_token in each sequence to 1\n# and the rest to 0\neos_token_id = tokenizer.eos_token_id\nfor idx, input_ids in enumerate(tokenized_data[\"input_ids\"]):\n    # Find all occurrences of eos_token\n    eos_positions = (input_ids == eos_token_id).nonzero(as_tuple=True)[0]\n    if eos_positions.nelement() > 0:  # Check if eos_token is present\n        first_eos_position = eos_positions[0]\n        tokenized_data[\"attention_mask\"][idx, first_eos_position] = 1  # Set the mask value to 1 for the first occurrence\n        \n        # Set the mask value to 0 for all subsequent occurrences\n        for subsequent_eos_position in eos_positions[1:]:\n            tokenized_data[\"attention_mask\"][idx, subsequent_eos_position] = 0\n"
  },
  {
    "type": "python",
    "code": "\"state\": \"{:.2f}\".format(state),\n"
  },
  {
    "type": "python",
    "code": "from jinja2 import nodes\nfrom jinja2.ext import Extension\n\nclass MarkdownExtension(Extension):\n    tags = set(['markdown'])\n\n    def __init__(self, environment):\n        super(MarkdownExtension, self).__init__(environment)\n\n    def parse(self, parser):\n        lineno = next(parser.stream).lineno\n\n        # Look for an `extra_attrs` option after the tag name\n        args = []\n        while not parser.stream.current.test_any('block_end'):\n            if parser.stream.skip_if('name:extra_attrs'):\n                parser.stream.skip(1)  # skip the equals sign\n                value = parser.stream.expect('string').value  # get the string value\n                extra_attrs = self.parse_extra_attrs(value)\n                args.append(nodes.Const(extra_attrs))\n            else:\n                parser.stream.next()\n\n        body = parser.parse_statements(['name:endmarkdown'], drop_needle=True)\n        return nodes.CallBlock(self.call_method('_render_markdown', args), [], [], body).set_lineno(lineno)\n\n    def parse_extra_attrs(self, value):\n        extra_attrs = {}\n        for part in value.split():\n            tag, attrs = part.split(':')\n            extra_attrs[tag] = attrs.split(',')\n        return extra_attrs\n\n    def _render_markdown(self, extra_attrs, caller):\n        # Use extra_attrs somehow...\n        return render_markdown(caller(), extra_attrs)\n"
  },
  {
    "type": "python",
    "code": "import os\nimport time\nimport glob\nfrom feature_extractor import FeatureExtractor  # Importing from the provided Python file\n\nclass FeatureExtractorDriver:\n    def __init__(self, raw_data_dir='raw_telemetry_data', structured_data_dir='structured_data'):\n        self.raw_data_dir = raw_data_dir\n        self.structured_data_dir = structured_data_dir\n        os.makedirs(self.structured_data_dir, exist_ok=True)\n        self.feature_extractor = FeatureExtractor()  # Initialize FeatureExtractor\n    \n    def structure_data(self):\n        # Example to process raw data files in raw_data_dir\n        # Adjust the logic as per the actual methods of feature_extractor.py and create_features.py\n        for file_path in glob.glob(os.path.join(self.raw_data_dir, '*.json')):\n            with open(file_path, 'r') as f:\n                raw_data = json.load(f)\n            # Process raw_data using feature_extractor and create_features.py\n            # Save the processed data in structured_data_dir in snapshot-x directories\n            # Implement the details based on the actual methods in the provided Python files\n            pass\n\n    def run(self, interval=60):\n        while True:\n            self.structure_data()\n            time.sleep(interval)\n\nif __name__ == \"__main__\":\n    driver = FeatureExtractorDriver()\n    driver.run()\n"
  },
  {
    "type": "python",
    "code": "def convert_to_triple_quoted(s):\n    # Escape triple double quotes\n    s = s.replace('\"\"\"', '\\\\\"\\\\\"\\\\\"')\n    \n    # Now wrap the whole string into triple double quotes\n    return f'\"\"\"{s}\"\"\"'\n\n# Test the function\nmultiline_string = \"\"\"\nThis is a multiline string.\nIt contains \"quotes\" and 'other' special characters.\nHere are some triple quotes: \"\"\" \"\"\"\n\"\"\"\n\nprint(convert_to_triple_quoted(multiline_string))\n"
  },
  {
    "type": "javascript",
    "code": "hfla_site | jekyll 3.9.2 | Error: Permission denied @ dir_s_mkdir - /srv/jekyll/_site\n"
  },
  {
    "type": "python",
    "code": "import pytest\nfrom my_module import read_file  # Replace with the actual module name\n\n# Define the test cases\ntest_cases = [\n    (\"/mnt/data/utf8_file.txt\", \"# coding: utf-8\\nThis is a text file.\"),\n    (\"/mnt/data/latin1_file.txt\", \"# coding: latin1\\nThis is a text file.\"),\n    (\"/mnt/data/ascii_file.txt\", \"# coding: ascii\\nThis is a text file.\"),\n    (\"/mnt/data/no_decl_file.txt\", \"This is a text file.\"),\n    (\"/mnt/data/invalid_decl_file.txt\", \"# coding: invalid\\nThis is a text file.\"),\n    (\"/mnt/data/empty_file.txt\", \"\"),\n]\n\n@pytest.mark.parametrize(\"filepath, expected\", test_cases)\ndef test_read_file(filepath, expected):\n    assert read_file(filepath) == expected\n"
  },
  {
    "type": "c",
    "code": "#ifdef MOD_PERSO\ncase 52:\n{\n    int status = MessageBox(NULL,\n        \"Allow OSC52 clipboard sync?\", \"PyTTY\", MB_OKCANCEL);\n\n    if (status == IDOK) {\n        base64_decodestate _d_state;\n        base64_init_decodestate(&_d_state);\n        char* d_out = malloc(term->osc_strlen);\n        if (!d_out) {\n            // Failed to allocate memory\n            break;\n        }\n\n        int d_count = base64_decode_block(\n            term->osc_string+1, term->osc_strlen-1, d_out, &_d_state);\n\n        uint32_t fmt;\n        wchar_t* buffer = NULL; // Changed to wchar_t\n\n        int cnt = MultiByteToWideChar(CP_UTF8, 0, (LPCCH)d_out, d_count, NULL, 0);\n        if (cnt > 0) {\n            buffer = calloc(cnt + 1, sizeof(wchar_t));\n            if (!buffer) {\n                // Failed to allocate memory\n                free(d_out);\n                break;\n            }\n            MultiByteToWideChar(CP_UTF8, 0, (LPCCH)d_out, d_count, buffer, cnt);\n        }\n\n        fmt = CF_UNICODETEXT;\n        if (buffer) {\n            int BufferSize = (wcslen(buffer) + 1) * sizeof(wchar_t);\n\n            HGLOBAL hData = GlobalAlloc(GMEM_MOVEABLE, BufferSize);\n            if (!hData) {\n                // Failed to allocate global memory\n                free(buffer);\n                free(d_out);\n                break;\n            }\n\n            void *GData = GlobalLock(hData);\n            if (!GData) {\n                // Failed to lock global memory\n                GlobalFree(hData);\n                free(buffer);\n                free(d_out);\n                break;\n            }\n\n            memcpy(GData, buffer, BufferSize);\n            GlobalUnlock(hData);\n\n            if (OpenClipboard(NULL)) {\n                EmptyClipboard();\n                if (!SetClipboardData(fmt, (HANDLE)hData)) {\n                    GlobalFree(hData);\n                }\n                CloseClipboard();\n            } else {\n                GlobalFree(hData);\n            }\n        }\n\n        free(buffer);\n        free(d_out);\n    }\n\n    break;\n}\n#endif\n"
  },
  {
    "type": "python",
    "code": "C0MPLEX = \"complex_project\",\n"
  },
  {
    "type": "javascript",
    "code": "_findChat(id) {\n    return Store.Chat.find(id._serialized || id);\n}\n"
  },
  {
    "type": "c",
    "code": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <sys/socket.h>\n#include <netinet/in.h>\n#include <arpa/inet.h>\n\nint main()\n{\n    int sockfd;\n    struct sockaddr_in addr;\n\n    // Create a socket\n    sockfd = socket(AF_INET, SOCK_DGRAM, 0);\n    if (sockfd < 0) {\n        perror(\"socket\");\n        exit(EXIT_FAILURE);\n    }\n\n    // Enable SO_REUSEADDR\n    int enable = 1;\n    if (setsockopt(sockfd, SOL_SOCKET, SO_REUSEADDR, &enable, sizeof(int)) < 0) {\n        perror(\"SO_REUSEADDR\");\n        exit(EXIT_FAILURE);\n    }\n\n    // Bind the socket to a specific IP address and port\n    memset(&addr, 0, sizeof(struct sockaddr_in));\n    addr.sin_family = AF_INET;\n    addr.sin_port = htons(12345);  // Port number\n    inet_pton(AF_INET, \"192.168.1.2\", &addr.sin_addr);  // IP address\n\n    if (bind(sockfd, (struct sockaddr *) &addr, sizeof(addr)) < 0) {\n        perror(\"bind\");\n        exit(EXIT_FAILURE);\n    }\n\n    printf(\"Socket successfully bound to %s:%d with SO_REUSEADDR enabled\\n\", \"192.168.1.2\", 12345);\n\n    // Now you can use the socket...\n\n    return 0;\n}\n"
  },
  {
    "type": "javascript",
    "code": "// In your ESLint rules file\n\nmodule.exports = {\n  rules: {\n    \"enforce-exception-handling\": {\n      create: function(context) {\n        let functionsThatThrow = new Set();\n\n        return {\n          FunctionDeclaration(node) {\n            const throwsComment = node.leadingComments && \n              node.leadingComments.find(comment => comment.value.includes(\"@throws\"));\n\n            if (throwsComment) {\n              functionsThatThrow.add(node.id.name);\n            }\n          },\n          CallExpression(node) {\n            if (functionsThatThrow.has(node.callee.name)) {\n              let parent = node.parent;\n\n              while (parent) {\n                if (parent.type === \"TryStatement\") return;\n                parent = parent.parent;\n              }\n\n              context.report({\n                node,\n                message: \"The function \" + node.callee.name + \" can throw an exception and needs to be called inside a try-catch block\"\n              });\n            }\n          }\n        };\n      }\n    }\n  }\n};\n"
  }
]